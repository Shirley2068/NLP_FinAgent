{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Importing the necessary libraries'''\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Import environment variables\n",
    "start_date = os.getenv('start_date')\n",
    "end_date = os.getenv('end_date')\n",
    "btc_etf_start_date = os.getenv('btc_etf_start_date')\n",
    "btc_etf_end_date = os.getenv('btc_etf_end_date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# # Fetch different commodities data\n",
    "\n",
    "# COMEX gold prices in USD\n",
    "gold_data = yf.download('GC=F',\n",
    "                        start=start_date,\n",
    "                        end=end_date)\n",
    "\n",
    "# COMEX silver prices in USD\n",
    "silver_data = yf.download('SI=F',\n",
    "                        start=start_date,\n",
    "                        end=end_date)\n",
    "\n",
    "# CRUDE oil prices in USD\n",
    "oil_data = yf.download('CL=F',\n",
    "                        start=start_date,\n",
    "                        end=end_date)\n",
    "\n",
    "# Combine all commodities into a single dataframe\n",
    "df_commodities = pd.concat([gold_data['Adj Close'],\n",
    "                            gold_data['Volume'],\n",
    "                            silver_data['Adj Close'],\n",
    "                            silver_data['Volume'],\n",
    "                            oil_data['Adj Close'],\n",
    "                            oil_data['Volume']], axis=1)\n",
    "\n",
    "df_commodities.columns = ['GOLD_ADJ_CLOSE', 'SILVER_ADJ_CLOSE', 'OIL_ADJ_CLOSE', 'GOLD_VOLUME', 'SILVER_VOLUME', 'OIL_VOLUME']\n",
    "\n",
    "# df_commodities.to_parquet('df_commodities.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Fetch historical values for currencies\n",
    "\n",
    "# EUR/USD\n",
    "eur_usd_data = yf.download('EURUSD=X',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# USD/JPY\n",
    "usd_jpy_data = yf.download('JPY=X',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# GBP/USD\n",
    "gbp_usd_data = yf.download('GBPUSD=X',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# EUR/USD\n",
    "usd_cny_data = yf.download('CNY=X',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# # Combine all currencies into a single dataframe\n",
    "# df_currencies = yf.download(\n",
    "# tickers = [\"EURUSD=X\", \"JPY=X\", \"GBPUSD=X\", \"CNY=X\"],\n",
    "# start = start_date,\n",
    "# end = end_date\n",
    "# )\n",
    "\n",
    "# Combine all commodities into a single dataframe\n",
    "df_currencies = pd.concat([eur_usd_data['Adj Close'],\n",
    "                            usd_jpy_data['Adj Close'],\n",
    "                            gbp_usd_data['Adj Close'],\n",
    "                            usd_cny_data['Adj Close']], axis=1)\n",
    "\n",
    "df_currencies.columns = ['EUR_USD_ADJ_CLOSE', 'USD_JPY_ADJ_CLOSE', 'GBP_USD_ADJ_CLOSE', 'USD_CNY_ADJ_CLOSE']\n",
    "\n",
    "# df_currencies.to_parquet('df_currencies.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Fetch financial market indices data\n",
    "\n",
    "# CBOE VIX\n",
    "vix_data = yf.download('^VIX',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# CBOE interest rate\n",
    "cboe_interest_rate_data = yf.download('^TNX',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "\n",
    "# 5 year treasury yield\n",
    "treasury_yield_5yrs_data = yf.download('^FVX',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "\n",
    "# 13 week treasury bill\n",
    "treasury_bill_13wk_data = yf.download('^IRX',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "\n",
    "# Russell 2000 index\n",
    "russel_2000_data = yf.download('^RUT',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "\n",
    "# iShares 20+ Year Treasury Bond ETF\n",
    "ishares_20yr_data = yf.download('TLT',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# # Combine all Financial market indices into a single dataframe\n",
    "# df_financial_ind = yf.download(\n",
    "# tickers = [\"^VIX\", \"^TNX\", \"^FVX\", \"^RUT\", \"TLT\", \"^IRX\"],\n",
    "# start = start_date,\n",
    "# end = end_date\n",
    "# )\n",
    "\n",
    "# Combine all commodities into a single dataframe\n",
    "df_financial_ind = pd.concat([vix_data['Adj Close'],\n",
    "                            cboe_interest_rate_data['Adj Close'],\n",
    "                            treasury_yield_5yrs_data['Adj Close'],\n",
    "                            treasury_bill_13wk_data['Adj Close'],\n",
    "                            russel_2000_data['Adj Close'],\n",
    "                            russel_2000_data['Volume'],\n",
    "                            ishares_20yr_data['Adj Close'],\n",
    "                            ishares_20yr_data['Volume']], axis=1)\n",
    "\n",
    "df_financial_ind.columns = ['VIX_ADJ_CLOSE', 'CBOE_INTEREST_RATE_ADJ_CLOSE', 'TREASURY_YIELD_5YRS_ADJ_CLOSE', 'TREASURY_BILL_13WK_ADJ_CLOSE', 'RUSSEL_2000_ADJ_CLOSE', 'RUSSEL_2000_VOLUME', 'ISHARES_20YR_ADJ_CLOSE', 'ISHARES_20YR_VOLUME']\n",
    "\n",
    "# df_financial_ind.to_parquet('df_financial_ind.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Fetch historical stock prices\n",
    "\n",
    "# Fetch historical values for TESLA\n",
    "tesla_data = yf.download('TSLA',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for AMD\n",
    "amd_data = yf.download('AMD',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for Intel\n",
    "intel_data = yf.download('INTC',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for Apple\n",
    "apple_data = yf.download('AAPL',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for NVDIA\n",
    "nvidia_data = yf.download('NVDA',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for META\n",
    "meta_data = yf.download('META',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for Google\n",
    "google_data = yf.download('GOOG',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# # Combine all Stock market prices into a single dataframe\n",
    "# df_stock = yf.download(\n",
    "# tickers = [\"TSLA\", \"AMD\", \"INTC\", \"AAPL\", \"NVDA\", \"META\", \"GOOG\"],\n",
    "# start = start_date,\n",
    "# end = end_date\n",
    "# )\n",
    "\n",
    "# Combine all commodities into a single dataframe\n",
    "df_stocks = pd.concat([ tesla_data['Adj Close'],\n",
    "                        tesla_data['Volume'],\n",
    "                        amd_data['Adj Close'],\n",
    "                        amd_data['Volume'],\n",
    "                        intel_data['Adj Close'],\n",
    "                        intel_data['Volume'], \n",
    "                        apple_data['Adj Close'],\n",
    "                        apple_data['Volume'],\n",
    "                        nvidia_data['Adj Close'],\n",
    "                        nvidia_data['Volume'],\n",
    "                        meta_data['Adj Close'],\n",
    "                        meta_data['Volume'],\n",
    "                        google_data['Adj Close'],\n",
    "                        google_data['Volume']], axis=1)\n",
    "\n",
    "df_stocks.columns = ['TESLA_ADJ_CLOSE', 'TESLA_VOLUME', 'AMD_ADJ_CLOSE', 'AMD_VOLUME', 'INTEL_ADJ_CLOSE', 'INTEL_VOLUME', 'APPLE_ADJ_CLOSE', 'APPLE_VOLUME', 'NVIDIA_ADJ_CLOSE', 'NVIDIA_VOLUME', 'META_ADJ_CLOSE', 'META_VOLUME', 'GOOGLE_ADJ_CLOSE', 'GOOGLE_VOLUME']\n",
    "\n",
    "# df_stocks.to_parquet('df_stocks.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Fetch BTC ETFs data\n",
    "\n",
    "# Fetch historical values for Grayscale Bitcoin Trust\n",
    "gbtc_data = yf.download('GBTC',\n",
    "                       start=btc_etf_start_date,\n",
    "                       end=btc_etf_end_date)\n",
    "\n",
    "# Fetch historical values for ARK 21Shares Bitcoin ETF\n",
    "arkb_data = yf.download('ARKB',\n",
    "                       start=btc_etf_start_date,\n",
    "                       end=btc_etf_end_date)\n",
    "\n",
    "# Fetch historical values for Bitwise Bitcoin ETF\n",
    "bitb_data = yf.download('BITB',\n",
    "                       start=btc_etf_start_date,\n",
    "                       end=btc_etf_end_date)\n",
    "\n",
    "# Fetch historical values for Fidelity Wise Origin Bitcoin Fund\n",
    "fbtc_data = yf.download('FBTC',\n",
    "                       start=btc_etf_start_date,\n",
    "                       end=btc_etf_end_date)\n",
    "\n",
    "# Fetch historical values for Invesco Galaxy Bitcoin ETF\n",
    "btco_data = yf.download('BTCO',\n",
    "                       start=btc_etf_start_date,\n",
    "                       end=btc_etf_end_date)\n",
    "\n",
    "# Fetch historical values for iShares Bitcoin Trust\n",
    "ibit_data = yf.download('IBIT',\n",
    "                       start=btc_etf_start_date,\n",
    "                       end=btc_etf_end_date)\n",
    "\n",
    "# Fetch historical values for VanEck Bitcoin Trust ETF\n",
    "hodl_data = yf.download('HODL',\n",
    "                       start=btc_etf_start_date,\n",
    "                       end=btc_etf_end_date)\n",
    "\n",
    "# Fetch historical values for ProShares Bitcoin Strategy ETF\n",
    "bito_data = yf.download('BITO',\n",
    "                       start=btc_etf_start_date,\n",
    "                       end=btc_etf_end_date)\n",
    "\n",
    "# # Combine all BTC ETFs into a single dataframe\n",
    "# df_btc_etfs = yf.download(\n",
    "# tickers = [\"GBTC\", \"ARKB\", \"BITB\", \"FBTC\", \"BTCO\", \"IBIT\", \"HODL\", \"BITO\"],\n",
    "# start = btc_etf_start_date,\n",
    "# end = btc_etf_end_date\n",
    "# )\n",
    "\n",
    "# Combine all commodities into a single dataframe\n",
    "df_btc_etf = pd.concat([ gbtc_data['Adj Close'],\n",
    "                        gbtc_data['Volume'],\n",
    "                        arkb_data['Adj Close'],\n",
    "                        arkb_data['Volume'],\n",
    "                        bitb_data['Adj Close'],\n",
    "                        bitb_data['Volume'],\n",
    "                        fbtc_data['Adj Close'],\n",
    "                        fbtc_data['Volume'],\n",
    "                        btco_data['Adj Close'],\n",
    "                        btco_data['Volume'],\n",
    "                        ibit_data['Adj Close'],\n",
    "                        ibit_data['Volume'],\n",
    "                        hodl_data['Adj Close'],\n",
    "                        hodl_data['Volume'],\n",
    "                        bito_data['Adj Close'],\n",
    "                        bito_data['Volume']], axis=1)\n",
    "\n",
    "df_btc_etf.columns = ['GBTC_ADJ_CLOSE', 'GBTC_VOLUME', 'ARKB_ADJ_CLOSE', 'ARKB_VOLUME', 'BITB_ADJ_CLOSE', 'BITB_VOLUME', 'FBTC_ADJ_CLOSE', 'FBTC_VOLUME', 'BTCO_ADJ_CLOSE', 'BTCO_VOLUME', 'IBIT_ADJ_CLOSE', 'IBIT_VOLUME', 'HODL_ADJ_CLOSE', 'HODL_VOLUME', 'BITO_ADJ_CLOSE', 'BITO_VOLUME']\n",
    "\n",
    "# df_btc_etf.to_parquet('df_btc_etf.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Fetch historical crypto prices\n",
    "\n",
    "# Fetch historical values for BTC-USD\n",
    "btc_usd_data = yf.download('BTC-USD',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for ETH-USD\n",
    "eth_usd_data = yf.download('ETH-USD',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for USDT-USD\n",
    "usdt_usd_data = yf.download('USDT-USD',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for USDC-USD\n",
    "usdc_usd_data = yf.download('USDC-USD',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for DOGE-USD\n",
    "doge_usd_data = yf.download('DOGE-USD',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for XRP-USD\n",
    "xrp_usd_data = yf.download('XRP-USD',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# Fetch historical values for SOL-USD\n",
    "sol_usd_data = yf.download('SOL-USD',\n",
    "                       start=start_date,\n",
    "                       end=end_date)\n",
    "\n",
    "# # Combine all dataframes into a single dataframe\n",
    "# df_crypto = yf.download(\n",
    "# tickers = [\"BTC-USD\", \"ETH-USD\", \"USDT-USD\", \"USDC-USD\", \"DOGE-USD\", \"XRP-USD\", \"SOL-USD\"],\n",
    "# start = start_date,\n",
    "# end = end_date\n",
    "# )\n",
    "\n",
    "# Combine all commodities into a single dataframe\n",
    "df_crypto_hist = pd.concat([btc_usd_data['Open'], \n",
    "                            btc_usd_data['High'], \n",
    "                            btc_usd_data['Low'], \n",
    "                            btc_usd_data['Close'], \n",
    "                            btc_usd_data['Volume'], \n",
    "                            btc_usd_data['Adj Close'],\n",
    "                            eth_usd_data['Adj Close'],\n",
    "                            eth_usd_data['Volume'],\n",
    "                            usdt_usd_data['Adj Close'],\n",
    "                            usdt_usd_data['Volume'],\n",
    "                            usdc_usd_data['Adj Close'],\n",
    "                            usdc_usd_data['Volume'],\n",
    "                            doge_usd_data['Adj Close'],\n",
    "                            doge_usd_data['Volume'],\n",
    "                            xrp_usd_data['Adj Close'],\n",
    "                            xrp_usd_data['Volume'],\n",
    "                            sol_usd_data['Adj Close'],\n",
    "                            sol_usd_data['Volume']], axis=1)\n",
    "\n",
    "df_crypto_hist.columns = ['BTC_OPEN', 'BTC_HIGH', 'BTC_LOW', 'BTC_CLOSE', 'BTC_VOLUME', 'BTC_ADJ_CLOSE', 'ETH_ADJ_CLOSE', 'ETH_VOLUME', 'USDT_ADJ_CLOSE', 'USDT_VOLUME', 'USDC_ADJ_CLOSE', 'USDC_VOLUME', 'DOGE_ADJ_CLOSE', 'DOGE_VOLUME', 'XRP_ADJ_CLOSE', 'XRP_VOLUME', 'SOL_ADJ_CLOSE', 'SOL_VOLUME']\n",
    "\n",
    "# df_crypto_hist.to_parquet('df_crypto_hist.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yfinance = pd.concat([df_commodities, df_currencies, df_financial_ind, df_stocks, df_btc_etf, df_crypto_hist], axis=1)\n",
    "\n",
    "# df_yfinance.to_parquet('df_yfinance.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "def load_environment_variables():\n",
    "    \"\"\"\n",
    "    Load environment variables and return them as a dictionary.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    env_vars = {\n",
    "        'start_date': os.getenv('start_date'),\n",
    "        'end_date': os.getenv('end_date'),\n",
    "        'btc_etf_start_date': os.getenv('btc_etf_start_date'),\n",
    "        'btc_etf_end_date': os.getenv('btc_etf_end_date')\n",
    "    }\n",
    "    return env_vars\n",
    "\n",
    "def download_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Download data for the given tickers within the specified date range.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data[ticker] = yf.download(ticker, start=start_date, end=end_date)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {ticker}: {e}\")\n",
    "    return data\n",
    "\n",
    "def create_dataframe(data, columns):\n",
    "    \"\"\"\n",
    "    Create a dataframe from the downloaded data and specify columns names.\n",
    "    \"\"\"\n",
    "    df = pd.concat(data, axis=1)\n",
    "    df.columns = columns\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    env_vars = load_environment_variables()\n",
    "    \n",
    "    # Define tickers for each category\n",
    "    commodities = ['GC=F', 'SI=F', 'CL=F']\n",
    "    currencies = ['EURUSD=X', 'JPY=X', 'GBPUSD=X', 'CNY=X']\n",
    "    financial_indices = ['^VIX', '^TNX', '^FVX', '^RUT', 'TLT', '^IRX']\n",
    "    stocks = ['TSLA', 'AMD', 'INTC', 'AAPL', 'NVDA', 'META', 'GOOG']\n",
    "    btc_etfs = ['GBTC', 'ARKB', 'BITB', 'FBTC', 'BTCO', 'IBIT', 'HODL', 'BITO']\n",
    "    cryptos = ['BTC-USD', 'ETH-USD', 'USDT-USD', 'USDC-USD', 'DOGE-USD', 'XRP-USD', 'SOL-USD']\n",
    "\n",
    "    # Download data\n",
    "    commodities_data = download_data(commodities, env_vars['start_date'], env_vars['end_date'])\n",
    "    currencies_data = download_data(currencies, env_vars['start_date'], env_vars['end_date'])\n",
    "    financial_indices_data = download_data(financial_indices, env_vars['start_date'], env_vars['end_date'])\n",
    "    stocks_data = download_data(stocks, env_vars['start_date'], env_vars['end_date'])\n",
    "    btc_etfs_data = download_data(btc_etfs, env_vars['btc_etf_start_date'], env_vars['btc_etf_end_date'])\n",
    "    cryptos_data = download_data(cryptos, env_vars['start_date'], env_vars['end_date'])\n",
    "\n",
    "    # Create dataframes\n",
    "    df_commodities = create_dataframe([commodities_data[ticker]['Adj Close'] for ticker in commodities] +\n",
    "                                      [commodities_data[ticker]['Volume'] for ticker in commodities],\n",
    "                                      ['GOLD_ADJ_CLOSE', 'SILVER_ADJ_CLOSE', 'OIL_ADJ_CLOSE',\n",
    "                                       'GOLD_VOLUME', 'SILVER_VOLUME', 'OIL_VOLUME'])\n",
    "    \n",
    "    df_currencies = create_dataframe([currencies_data[ticker]['Adj Close'] for ticker in currencies],\n",
    "                                     ['EUR_USD_ADJ_CLOSE', 'USD_JPY_ADJ_CLOSE', 'GBP_USD_ADJ_CLOSE', 'USD_CNY_ADJ_CLOSE'])\n",
    "\n",
    "    df_financial_ind = create_dataframe([financial_indices_data[ticker]['Adj Close'] for ticker in financial_indices] +\n",
    "                                        [financial_indices_data['^RUT']['Volume'], financial_indices_data['TLT']['Volume']],\n",
    "                                        ['VIX_ADJ_CLOSE', 'CBOE_INTEREST_RATE_ADJ_CLOSE', 'TREASURY_YIELD_5YRS_ADJ_CLOSE',\n",
    "                                         'RUSSEL_2000_ADJ_CLOSE', 'ISHARES_20YR_ADJ_CLOSE', 'TREASURY_BILL_13WK_ADJ_CLOSE',\n",
    "                                         'RUSSEL_2000_VOLUME', 'ISHARES_20YR_VOLUME'])\n",
    "\n",
    "    df_stocks = create_dataframe([stocks_data[ticker]['Adj Close'] for ticker in stocks] +\n",
    "                                 [stocks_data[ticker]['Volume'] for ticker in stocks],\n",
    "                                 ['TESLA_ADJ_CLOSE', 'AMD_ADJ_CLOSE', 'INTEL_ADJ_CLOSE', 'APPLE_ADJ_CLOSE', 'NVIDIA_ADJ_CLOSE', 'META_ADJ_CLOSE', 'GOOGLE_ADJ_CLOSE',\n",
    "                                  'TESLA_VOLUME', 'AMD_VOLUME', 'INTEL_VOLUME', 'APPLE_VOLUME', 'NVIDIA_VOLUME', 'META_VOLUME', 'GOOGLE_VOLUME'])\n",
    "\n",
    "    df_btc_etf = create_dataframe([btc_etfs_data[ticker]['Adj Close'] for ticker in btc_etfs] +\n",
    "                                  [btc_etfs_data[ticker]['Volume'] for ticker in btc_etfs],\n",
    "                                  ['GBTC_ADJ_CLOSE', 'ARKB_ADJ_CLOSE', 'BITB_ADJ_CLOSE', 'FBTC_ADJ_CLOSE', 'BTCO_ADJ_CLOSE', 'IBIT_ADJ_CLOSE', 'HODL_ADJ_CLOSE', 'BITO_ADJ_CLOSE',\n",
    "                                   'GBTC_VOLUME', 'ARKB_VOLUME', 'BITB_VOLUME', 'FBTC_VOLUME', 'BTCO_VOLUME', 'IBIT_VOLUME', 'HODL_VOLUME', 'BITO_VOLUME'])\n",
    "\n",
    "    # Start by extracting BTC data with specific columns\n",
    "    btc_data = cryptos_data['BTC-USD'][['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "    btc_data.columns = ['BTC_OPEN', 'BTC_HIGH', 'BTC_LOW', 'BTC_CLOSE', 'BTC_ADJ_CLOSE', 'BTC_VOLUME']\n",
    "\n",
    "    # Now process other cryptocurrencies\n",
    "    other_crypto_data = []\n",
    "    for ticker in cryptos[1:]:  # Assuming 'cryptos' list starts with 'BTC-USD'\n",
    "        ticker_data = cryptos_data[ticker][['Adj Close', 'Volume']]\n",
    "        ticker_data.columns = [f'{ticker[:-4]}_ADJ_CLOSE', f'{ticker[:-4]}_VOLUME']\n",
    "        other_crypto_data.append(ticker_data)\n",
    "\n",
    "    # Concatenate BTC data with other cryptocurrencies data\n",
    "    df_crypto_hist = pd.concat([btc_data] + other_crypto_data, axis=1)\n",
    "\n",
    "    df_crypto_hist.columns = ['BTC_OPEN', 'BTC_HIGH', 'BTC_LOW', 'BTC_CLOSE', 'BTC_ADJ_CLOSE', 'BTC_VOLUME',\n",
    "                              'ETH_ADJ_CLOSE', 'ETH_VOLUME', 'USDT_ADJ_CLOSE', 'USDT_VOLUME',\n",
    "                              'USDC_ADJ_CLOSE', 'USDC_VOLUME', 'DOGE_ADJ_CLOSE', 'DOGE_VOLUME',\n",
    "                              'XRP_ADJ_CLOSE', 'XRP_VOLUME', 'SOL_ADJ_CLOSE', 'SOL_VOLUME']\n",
    "\n",
    "    # Concatenate all dataframes into a single dataframe\n",
    "    df_yfinance = pd.concat([df_commodities, df_currencies, df_financial_ind, df_stocks, df_btc_etf, df_crypto_hist], axis=1)\n",
    "    \n",
    "    df_yfinance.to_parquet('df_yfinance.parquet.gzip', compression='gzip')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
