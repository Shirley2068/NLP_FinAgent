{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "import mplfinance as mpf\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options to show all columns and rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()  # get current working directory\n",
    "\n",
    "# Get the parent directory of the current working directory\n",
    "grandparent_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "end_date = '2024-04-01'\n",
    "end_date = datetime.strptime(end_date, '%Y-%m-%d')  # Convert end_date to datetime object\n",
    "new_date = end_date - timedelta(days=1)  # Subtract 1 day from end_date\n",
    "\n",
    "new_date_str = new_date.strftime('%Y-%m-%d')  # Convert new_date back to string format\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Import environment variables\n",
    "start_date = os.getenv('start_date')\n",
    "end_date = os.getenv('end_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Data Table - Without Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_parquet(os.path.join(grandparent_dir, \"data\\\\processed\\\\files\\\\processed_data.parquet.gzip\"))\n",
    "\n",
    "df_final.rename(columns={'value': 'btc_fear_and_greed_index'}, inplace=True)\n",
    "\n",
    "columns_to_delete = ['BTC_VOLUME', 'value_classification', 'Adj_Close']\n",
    "\n",
    "# Delete the specified columns\n",
    "df_final = df_final.drop(columns=columns_to_delete)\n",
    "\n",
    "# Convert column names to uppercase\n",
    "df_final.columns = df_final.columns.str.upper()\n",
    "\n",
    "df_final.columns = df_final.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.set_index('DATE', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y variable - Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "ax[0].plot(df_final.BTC_DAILY_ABSOLUTE_CHANGE)\n",
    "ax[0].set_title('BTC Absolute Price Change')\n",
    "ax[1].plot(df_final.BTC_DAILY_RETURNS_PERC)\n",
    "ax[1].set_title('BTC Daily Returns (%)')\n",
    "ax[2].plot(df_final.BTC_LOG_DIFFERENCE)\n",
    "ax[2].set_title('BTC Log Difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity - Unit root testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit root testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Functions for numeric data preprocessing. '''\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "from termcolor import colored\n",
    "from scipy.signal import argrelmin, argrelmax\n",
    "from scipy.signal._peak_finding import _boolrelextrema\n",
    "from arch.unitroot import ADF, PhillipsPerron, KPSS\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_root_testing(df: pd.DataFrame, conf: float = 0.05, verbose: bool = False, tabsize: int = 30):\n",
    "    ''' \n",
    "    Checks stationarity of all columns of a given pandas df using\n",
    "    • Augmented Dickey-Fuller (ADF), \n",
    "    • Phillips-Perron (PP)\n",
    "    • Kwiatkowski-Phillips-Schmidt-Shin (KPSS)\n",
    "    unit root tests. \n",
    "    '''\n",
    "    def print_result(name, p_value):\n",
    "        if p_value <= conf:\n",
    "            return colored(f'{p_value:.4f}', \"green\")  # Reject null hypothesis\n",
    "        else:\n",
    "            return colored(f'{p_value:.4f}', \"red\")    # Don't reject null hypothesis\n",
    "\n",
    "    if verbose:\n",
    "        print('ADF test:\\n H0: unit root, H1: stationarity\\n')\n",
    "        for column in df.columns:\n",
    "            p_value = np.round(ADF(df[column].dropna()).pvalue, 5)\n",
    "            reject = p_value <= conf\n",
    "            print(f' {column} : \\tp = {print_result(\"ADF\", p_value)} {\"<\" if reject else \">\"} {conf} \\t-> {\"reject\" if reject else \"don`t reject\"} H0 @ {100*conf}% conf.'.expandtabs(tabsize))\n",
    "\n",
    "        print('\\n------------------------------------------------------------------------------------------\\n')     \n",
    "        print('PP test:\\n H0: unit root, H1: stationarity\\n')\n",
    "        for column in df.columns:\n",
    "            p_value = np.round(PhillipsPerron(df[column].dropna()).pvalue, 5)\n",
    "            reject = p_value <= conf\n",
    "            print(f' {column} : \\tp = {print_result(\"PP\", p_value)} {\"<\" if reject else \">\"} {conf} \\t-> {\"reject\" if reject else \"don`t reject\"} H0 @ {100*conf}% conf.'.expandtabs(tabsize))\n",
    "\n",
    "        print('\\n------------------------------------------------------------------------------------------\\n')     \n",
    "        print('KPSS test:\\n H0: stationarity, H1: unit root\\n')\n",
    "        for column in df.columns:\n",
    "            p_value = np.round(KPSS(df[column].dropna()).pvalue, 5)\n",
    "            reject = p_value > conf\n",
    "            print(f' {column} : \\tt = {print_result(\"KPSS\", p_value)} {\"<\" if reject else \">\"} {conf} \\t-> {\"reject\" if reject else \"don`t reject\"} H0 @ {100*conf}% conf.'.expandtabs(tabsize))\n",
    "\n",
    "    else:\n",
    "        print('Results of ADF, PP and KPSS tests by column (p-values):\\n')\n",
    "        for column in df.columns:\n",
    "            try:\n",
    "                p_value = ADF(df[column].dropna()).pvalue\n",
    "                ADF_result = print_result(\"ADF\", p_value)\n",
    "            except Exception as e:\n",
    "                ADF_result = colored(type(e).__name__, \"cyan\")\n",
    "\n",
    "            try:\n",
    "                p_value = PhillipsPerron(df[column].dropna()).pvalue\n",
    "                PP_result = print_result(\"PP\", p_value)\n",
    "            except Exception as e:\n",
    "                PP_result = colored(type(e).__name__, \"cyan\")\n",
    "\n",
    "            try:\n",
    "                p_value = KPSS(df[column].dropna()).pvalue\n",
    "                KPSS_result = print_result(\"KPSS\", p_value)\n",
    "            except Exception as e:\n",
    "                KPSS_result = colored(type(e).__name__, \"cyan\")\n",
    "\n",
    "            print(f'{column} --\\t ADF: {ADF_result},\\tPP: {PP_result},\\tKPSS: {KPSS_result}'.expandtabs(tabsize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of ADF, PP and KPSS tests by column (p-values):\n",
      "\n",
      "OPEN --                                            ADF: \u001b[31m0.8563\u001b[0m,                            PP: \u001b[31m0.9292\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "HIGH --                                            ADF: \u001b[31m0.8544\u001b[0m,                            PP: \u001b[31m0.9336\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "LOW --                                             ADF: \u001b[31m0.8807\u001b[0m,                            PP: \u001b[31m0.9384\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "CLOSE --                                           ADF: \u001b[31m0.8719\u001b[0m,                            PP: \u001b[31m0.9401\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "ADJ_CLOSE --                                       ADF: \u001b[31m0.8719\u001b[0m,                            PP: \u001b[31m0.9401\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLUME --                                          ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GOLD_ADJ_CLOSE --                                  ADF: \u001b[31m0.8965\u001b[0m,                            PP: \u001b[31m0.8750\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "SILVER_ADJ_CLOSE --                                ADF: \u001b[31m0.3197\u001b[0m,                            PP: \u001b[31m0.3716\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "OIL_ADJ_CLOSE --                                   ADF: \u001b[31m0.3971\u001b[0m,                            PP: \u001b[31m0.2939\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GOLD_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1937\u001b[0m\n",
      "SILVER_VOLUME --                                   ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.5673\u001b[0m\n",
      "OIL_VOLUME --                                      ADF: \u001b[32m0.0413\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "EUR_USD_ADJ_CLOSE --                               ADF: \u001b[31m0.3390\u001b[0m,                            PP: \u001b[31m0.3930\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "USD_JPY_ADJ_CLOSE --                               ADF: \u001b[31m0.9807\u001b[0m,                            PP: \u001b[31m0.9801\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GBP_USD_ADJ_CLOSE --                               ADF: \u001b[31m0.1683\u001b[0m,                            PP: \u001b[31m0.2040\u001b[0m,                              KPSS: \u001b[32m0.0002\u001b[0m\n",
      "USD_CNY_ADJ_CLOSE --                               ADF: \u001b[31m0.4804\u001b[0m,                            PP: \u001b[31m0.6203\u001b[0m,                              KPSS: \u001b[32m0.0006\u001b[0m\n",
      "VIX_ADJ_CLOSE --                                   ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0309\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\arch\\unitroot\\unitroot.py:167: RuntimeWarning: invalid value encountered in log\n",
      "  llf = -nobs / 2.0 * (log(2 * pi) + log(sigma2) + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOE_INTEREST_RATE_ADJ_CLOSE --                    ADF: \u001b[31m0.9116\u001b[0m,                            PP: \u001b[31m0.9115\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREASURY_YIELD_5YRS_ADJ_CLOSE --                   ADF: \u001b[31m0.9334\u001b[0m,                            PP: \u001b[31m0.9294\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "RUSSEL_2000_ADJ_CLOSE --                           ADF: \u001b[31m0.4338\u001b[0m,                            PP: \u001b[31m0.3923\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "ISHARES_20YR_ADJ_CLOSE --                          ADF: \u001b[31m0.8238\u001b[0m,                            PP: \u001b[31m0.8003\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREASURY_BILL_13WK_ADJ_CLOSE --                    ADF: \u001b[31m0.9800\u001b[0m,                            PP: \u001b[31m0.9908\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "RUSSEL_2000_VOLUME --                              ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0030\u001b[0m\n",
      "ISHARES_20YR_VOLUME --                             ADF: \u001b[31m0.2391\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TESLA_ADJ_CLOSE --                                 ADF: \u001b[31m0.4887\u001b[0m,                            PP: \u001b[31m0.5090\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "AMD_ADJ_CLOSE --                                   ADF: \u001b[31m0.9320\u001b[0m,                            PP: \u001b[31m0.9195\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "INTEL_ADJ_CLOSE --                                 ADF: \u001b[31m0.1570\u001b[0m,                            PP: \u001b[31m0.1711\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "APPLE_ADJ_CLOSE --                                 ADF: \u001b[31m0.7745\u001b[0m,                            PP: \u001b[31m0.7699\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "NVIDIA_ADJ_CLOSE --                                ADF: \u001b[31m1.0000\u001b[0m,                            PP: \u001b[31m1.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "META_ADJ_CLOSE --                                  ADF: \u001b[31m0.9775\u001b[0m,                            PP: \u001b[31m0.9748\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GOOGLE_ADJ_CLOSE --                                ADF: \u001b[31m0.8961\u001b[0m,                            PP: \u001b[31m0.8837\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TESLA_VOLUME --                                    ADF: \u001b[32m0.0036\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0017\u001b[0m\n",
      "AMD_VOLUME --                                      ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0893\u001b[0m\n",
      "INTEL_VOLUME --                                    ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "APPLE_VOLUME --                                    ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "NVIDIA_VOLUME --                                   ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0853\u001b[0m\n",
      "META_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0451\u001b[0m\n",
      "GOOGLE_VOLUME --                                   ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GBTC_ADJ_CLOSE --                                  ADF: \u001b[31m0.9981\u001b[0m,                            PP: \u001b[31m1.0000\u001b[0m,                              KPSS: \u001b[32m0.0139\u001b[0m\n",
      "ARKB_ADJ_CLOSE --                                  ADF: \u001b[31m0.0769\u001b[0m,                            PP: \u001b[31m0.9987\u001b[0m,                              KPSS: \u001b[31m0.0602\u001b[0m\n",
      "BITB_ADJ_CLOSE --                                  ADF: \u001b[31m0.1365\u001b[0m,                            PP: \u001b[31m0.9986\u001b[0m,                              KPSS: \u001b[31m0.0618\u001b[0m\n",
      "FBTC_ADJ_CLOSE --                                  ADF: \u001b[31m0.0898\u001b[0m,                            PP: \u001b[31m0.9987\u001b[0m,                              KPSS: \u001b[31m0.0598\u001b[0m\n",
      "BTCO_ADJ_CLOSE --                                  ADF: \u001b[31m0.1038\u001b[0m,                            PP: \u001b[31m0.9989\u001b[0m,                              KPSS: \u001b[31m0.0565\u001b[0m\n",
      "IBIT_ADJ_CLOSE --                                  ADF: \u001b[31m0.0914\u001b[0m,                            PP: \u001b[31m0.9987\u001b[0m,                              KPSS: \u001b[31m0.0592\u001b[0m\n",
      "HODL_ADJ_CLOSE --                                  ADF: \u001b[31m0.0862\u001b[0m,                            PP: \u001b[31m0.9987\u001b[0m,                              KPSS: \u001b[31m0.0600\u001b[0m\n",
      "BITO_ADJ_CLOSE --                                  ADF: \u001b[32m0.0076\u001b[0m,                            PP: \u001b[31m0.9990\u001b[0m,                              KPSS: \u001b[32m0.0383\u001b[0m\n",
      "GBTC_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0042\u001b[0m\n",
      "ARKB_VOLUME --                                     ADF: \u001b[32m0.0417\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0036\u001b[0m\n",
      "BITB_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0072\u001b[0m\n",
      "FBTC_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0300\u001b[0m\n",
      "BTCO_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0124\u001b[0m\n",
      "IBIT_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9974\u001b[0m\n",
      "HODL_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1816\u001b[0m\n",
      "BITO_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2532\u001b[0m\n",
      "ETH_ADJ_CLOSE --                                   ADF: \u001b[31m0.8069\u001b[0m,                            PP: \u001b[31m0.7790\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "ETH_VOLUME --                                      ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "USDT_ADJ_CLOSE --                                  ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0163\u001b[0m\n",
      "USDT_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "USDC_ADJ_CLOSE --                                  ADF: \u001b[32m0.0043\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "USDC_VOLUME --                                     ADF: \u001b[36mInfeasibleTestException\u001b[0m,           PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.4964\u001b[0m\n",
      "DOGE_ADJ_CLOSE --                                  ADF: \u001b[31m0.0969\u001b[0m,                            PP: \u001b[31m0.1072\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "DOGE_VOLUME --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0179\u001b[0m\n",
      "XRP_ADJ_CLOSE --                                   ADF: \u001b[32m0.0025\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0264\u001b[0m\n",
      "XRP_VOLUME --                                      ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0064\u001b[0m\n",
      "SOL_ADJ_CLOSE --                                   ADF: \u001b[31m0.7699\u001b[0m,                            PP: \u001b[31m0.9029\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "SOL_VOLUME --                                      ADF: \u001b[32m0.0430\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GAS_ADJ_CLOSE --                                   ADF: \u001b[32m0.0028\u001b[0m,                            PP: \u001b[31m0.0681\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GAS_VOLUME --                                      ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2873\u001b[0m\n",
      "GAS_USD --                                         ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0077\u001b[0m,                              KPSS: \u001b[32m0.0007\u001b[0m\n",
      "EXTREME_FEAR --                                    ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1320\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\arch\\unitroot\\unitroot.py:167: RuntimeWarning: invalid value encountered in log\n",
      "  llf = -nobs / 2.0 * (log(2 * pi) + log(sigma2) + 1)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\arch\\unitroot\\unitroot.py:167: RuntimeWarning: invalid value encountered in log\n",
      "  llf = -nobs / 2.0 * (log(2 * pi) + log(sigma2) + 1)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\arch\\unitroot\\unitroot.py:167: RuntimeWarning: invalid value encountered in log\n",
      "  llf = -nobs / 2.0 * (log(2 * pi) + log(sigma2) + 1)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\arch\\unitroot\\unitroot.py:167: RuntimeWarning: invalid value encountered in log\n",
      "  llf = -nobs / 2.0 * (log(2 * pi) + log(sigma2) + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTREME_GREED --                                   ADF: \u001b[32m0.0002\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0847\u001b[0m\n",
      "FEAR --                                            ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0009\u001b[0m\n",
      "GREED --                                           ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0219\u001b[0m\n",
      "NEUTRAL --                                         ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0065\u001b[0m\n",
      "SP500_ADJUSTED --                                  ADF: \u001b[31m0.9534\u001b[0m,                            PP: \u001b[31m0.9410\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GDP --                                             ADF: \u001b[31m0.8981\u001b[0m,                            PP: \u001b[31m0.9879\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "RGDP --                                            ADF: \u001b[31m0.5277\u001b[0m,                            PP: \u001b[31m0.9172\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "UNRATE --                                          ADF: \u001b[32m0.0034\u001b[0m,                            PP: \u001b[31m0.2401\u001b[0m,                              KPSS: \u001b[32m0.0034\u001b[0m\n",
      "CPI --                                             ADF: \u001b[31m0.9869\u001b[0m,                            PP: \u001b[31m1.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "INTEREST_RATE_ADJUSTED --                          ADF: \u001b[31m0.7894\u001b[0m,                            PP: \u001b[31m0.7899\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREASURE_MATURITY_ADJUSTED --                      ADF: \u001b[31m0.7516\u001b[0m,                            PP: \u001b[31m0.7961\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "INFLATION_RATE_ADJUSTED --                         ADF: \u001b[31m0.5801\u001b[0m,                            PP: \u001b[31m0.5465\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "STICKY_CPI --                                      ADF: \u001b[31m0.5707\u001b[0m,                            PP: \u001b[31m0.8614\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "M2_MONEY_STOCK_ADJUSTED --                         ADF: \u001b[31m0.5327\u001b[0m,                            PP: \u001b[31m0.5110\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLUME_ADI --                                      ADF: \u001b[36mInfeasibleTestException\u001b[0m,           PP: \u001b[31m0.9263\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLUME_OBV --                                      ADF: \u001b[36mInfeasibleTestException\u001b[0m,           PP: \u001b[31m0.6218\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLUME_CMF --                                      ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1198\u001b[0m\n",
      "VOLUME_FI --                                       ADF: \u001b[36mInfeasibleTestException\u001b[0m,           PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.5382\u001b[0m\n",
      "VOLUME_EM --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1650\u001b[0m\n",
      "VOLUME_SMA_EM --                                   ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1689\u001b[0m\n",
      "VOLUME_VPT --                                      ADF: \u001b[31m0.7726\u001b[0m,                            PP: \u001b[31m0.7801\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLUME_VWAP --                                     ADF: \u001b[31m0.7812\u001b[0m,                            PP: \u001b[31m0.9421\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLUME_MFI --                                      ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2959\u001b[0m\n",
      "VOLUME_NVI --                                      ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0002\u001b[0m\n",
      "VOLATILITY_BBM --                                  ADF: \u001b[31m0.7459\u001b[0m,                            PP: \u001b[31m0.9570\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLATILITY_BBH --                                  ADF: \u001b[31m0.8534\u001b[0m,                            PP: \u001b[31m0.9376\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLATILITY_BBL --                                  ADF: \u001b[31m0.8609\u001b[0m,                            PP: \u001b[31m0.9081\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLATILITY_BBW --                                  ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0040\u001b[0m\n",
      "VOLATILITY_BBP --                                  ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2043\u001b[0m\n",
      "VOLATILITY_BBHI --                                 ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2104\u001b[0m\n",
      "VOLATILITY_BBLI --                                 ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.4605\u001b[0m\n",
      "VOLATILITY_KCC --                                  ADF: \u001b[31m0.8512\u001b[0m,                            PP: \u001b[31m0.9439\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLATILITY_KCH --                                  ADF: \u001b[31m0.8116\u001b[0m,                            PP: \u001b[31m0.9384\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLATILITY_KCL --                                  ADF: \u001b[31m0.7936\u001b[0m,                            PP: \u001b[31m0.9415\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLATILITY_KCW --                                  ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0159\u001b[0m\n",
      "VOLATILITY_KCP --                                  ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2401\u001b[0m\n",
      "VOLATILITY_KCHI --                                 ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.5438\u001b[0m\n",
      "VOLATILITY_KCLI --                                 ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0113\u001b[0m\n",
      "VOLATILITY_DCL --                                  ADF: \u001b[31m0.9169\u001b[0m,                            PP: \u001b[31m0.9142\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLATILITY_DCH --                                  ADF: \u001b[31m0.9352\u001b[0m,                            PP: \u001b[31m0.9462\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLATILITY_DCM --                                  ADF: \u001b[31m0.8117\u001b[0m,                            PP: \u001b[31m0.9548\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLATILITY_DCW --                                  ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0037\u001b[0m\n",
      "VOLATILITY_DCP --                                  ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1738\u001b[0m\n",
      "VOLATILITY_ATR --                                  ADF: \u001b[31m0.4241\u001b[0m,                            PP: \u001b[31m0.2054\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "VOLATILITY_UI --                                   ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0048\u001b[0m\n",
      "TREND_MACD --                                      ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1356\u001b[0m\n",
      "TREND_MACD_SIGNAL --                               ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0001\u001b[0m,                              KPSS: \u001b[31m0.1303\u001b[0m\n",
      "TREND_MACD_DIFF --                                 ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9935\u001b[0m\n",
      "TREND_SMA_FAST --                                  ADF: \u001b[31m0.7915\u001b[0m,                            PP: \u001b[31m0.9449\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_SMA_SLOW --                                  ADF: \u001b[31m0.6416\u001b[0m,                            PP: \u001b[31m0.9649\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_EMA_FAST --                                  ADF: \u001b[31m0.7846\u001b[0m,                            PP: \u001b[31m0.9571\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_EMA_SLOW --                                  ADF: \u001b[31m0.7611\u001b[0m,                            PP: \u001b[31m0.9692\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_VORTEX_IND_POS --                            ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2196\u001b[0m\n",
      "TREND_VORTEX_IND_NEG --                            ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2068\u001b[0m\n",
      "TREND_VORTEX_IND_DIFF --                           ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2117\u001b[0m\n",
      "TREND_TRIX --                                      ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0637\u001b[0m\n",
      "TREND_MASS_INDEX --                                ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2204\u001b[0m\n",
      "TREND_DPO --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.4976\u001b[0m\n",
      "TREND_KST --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0967\u001b[0m\n",
      "TREND_KST_SIG --                                   ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0849\u001b[0m\n",
      "TREND_KST_DIFF --                                  ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9953\u001b[0m\n",
      "TREND_ICHIMOKU_CONV --                             ADF: \u001b[31m0.8477\u001b[0m,                            PP: \u001b[31m0.9360\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_ICHIMOKU_BASE --                             ADF: \u001b[31m0.6769\u001b[0m,                            PP: \u001b[31m0.9667\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_ICHIMOKU_A --                                ADF: \u001b[31m0.8108\u001b[0m,                            PP: \u001b[31m0.9590\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_ICHIMOKU_B --                                ADF: \u001b[31m0.9379\u001b[0m,                            PP: \u001b[31m0.9649\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_STC --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.7620\u001b[0m\n",
      "TREND_ADX --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.6087\u001b[0m\n",
      "TREND_ADX_POS --                                   ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.3078\u001b[0m\n",
      "TREND_ADX_NEG --                                   ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0526\u001b[0m\n",
      "TREND_CCI --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1961\u001b[0m\n",
      "TREND_VISUAL_ICHIMOKU_A --                         ADF: \u001b[31m0.8497\u001b[0m,                            PP: \u001b[31m0.9104\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_VISUAL_ICHIMOKU_B --                         ADF: \u001b[31m0.9062\u001b[0m,                            PP: \u001b[31m0.9382\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_AROON_UP --                                  ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0443\u001b[0m\n",
      "TREND_AROON_DOWN --                                ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2680\u001b[0m\n",
      "TREND_AROON_IND --                                 ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1313\u001b[0m\n",
      "TREND_PSAR_UP --                                   ADF: \u001b[31m0.7653\u001b[0m,                            PP: \u001b[31m0.9054\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_PSAR_DOWN --                                 ADF: \u001b[31m0.8839\u001b[0m,                            PP: \u001b[31m0.8701\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TREND_PSAR_UP_INDICATOR --                         ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.8595\u001b[0m\n",
      "TREND_PSAR_DOWN_INDICATOR --                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9586\u001b[0m\n",
      "MOMENTUM_RSI --                                    ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1006\u001b[0m\n",
      "MOMENTUM_STOCH_RSI --                              ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9549\u001b[0m\n",
      "MOMENTUM_STOCH_RSI_K --                            ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9073\u001b[0m\n",
      "MOMENTUM_STOCH_RSI_D --                            ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9740\u001b[0m\n",
      "MOMENTUM_TSI --                                    ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1196\u001b[0m\n",
      "MOMENTUM_UO --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1583\u001b[0m\n",
      "MOMENTUM_STOCH --                                  ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1275\u001b[0m\n",
      "MOMENTUM_STOCH_SIGNAL --                           ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1272\u001b[0m\n",
      "MOMENTUM_WR --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1275\u001b[0m\n",
      "MOMENTUM_AO --                                     ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1369\u001b[0m\n",
      "MOMENTUM_ROC --                                    ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2817\u001b[0m\n",
      "MOMENTUM_PPO --                                    ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0795\u001b[0m\n",
      "MOMENTUM_PPO_SIGNAL --                             ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0630\u001b[0m\n",
      "MOMENTUM_PPO_HIST --                               ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9927\u001b[0m\n",
      "MOMENTUM_PVO --                                    ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.5063\u001b[0m\n",
      "MOMENTUM_PVO_SIGNAL --                             ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.4280\u001b[0m\n",
      "MOMENTUM_PVO_HIST --                               ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9955\u001b[0m\n",
      "MOMENTUM_KAMA --                                   ADF: \u001b[31m0.9247\u001b[0m,                            PP: \u001b[31m0.9547\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "OTHERS_DR --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.3659\u001b[0m\n",
      "OTHERS_DLR --                                      ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.3014\u001b[0m\n",
      "OTHERS_CR --                                       ADF: \u001b[31m0.8719\u001b[0m,                            PP: \u001b[31m0.9401\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "UNIQUE_USERS --                                    ADF: \u001b[31m0.1534\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "FOLLOWERS --                                       ADF: \u001b[31m0.2552\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "TWEET_COUNT --                                     ADF: \u001b[31m0.1984\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "BTC_PERCENTAGE_DOMINANCE --                        ADF: \u001b[31m0.2269\u001b[0m,                            PP: \u001b[31m0.3437\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "ETH_PERCENTAGE_DOMINANCE --                        ADF: \u001b[31m0.3785\u001b[0m,                            PP: \u001b[31m0.3281\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "USDT_PERCENTAGE_DOMINANCE --                       ADF: \u001b[31m0.4447\u001b[0m,                            PP: \u001b[31m0.4329\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "BNB_PERCENTAGE_DOMINANCE --                        ADF: \u001b[31m0.5791\u001b[0m,                            PP: \u001b[31m0.5732\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "SOL_PERCENTAGE_DOMINANCE --                        ADF: \u001b[31m0.9736\u001b[0m,                            PP: \u001b[31m0.9680\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "OTHERS_PERCENTAGE_DOMINANCE --                     ADF: \u001b[32m0.0444\u001b[0m,                            PP: \u001b[32m0.0117\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPR --                                             ADF: \u001b[32m0.0125\u001b[0m,                            PP: \u001b[32m0.0068\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRT --                                            ADF: \u001b[32m0.0077\u001b[0m,                            PP: \u001b[32m0.0037\u001b[0m,                              KPSS: \u001b[32m0.0041\u001b[0m\n",
      "GPRA --                                            ADF: \u001b[31m0.0625\u001b[0m,                            PP: \u001b[32m0.0439\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRH --                                            ADF: \u001b[32m0.0341\u001b[0m,                            PP: \u001b[32m0.0225\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHT --                                           ADF: \u001b[32m0.0053\u001b[0m,                            PP: \u001b[32m0.0024\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHA --                                           ADF: \u001b[31m0.2470\u001b[0m,                            PP: \u001b[31m0.2177\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "SHARE_GPR --                                       ADF: \u001b[32m0.0125\u001b[0m,                            PP: \u001b[32m0.0067\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "N10 --                                             ADF: \u001b[31m0.5487\u001b[0m,                            PP: \u001b[31m0.5308\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "SHARE_GPRH --                                      ADF: \u001b[32m0.0339\u001b[0m,                            PP: \u001b[32m0.0223\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "N3H --                                             ADF: \u001b[31m0.1345\u001b[0m,                            PP: \u001b[31m0.1076\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRH_NOEW --                                       ADF: \u001b[32m0.0126\u001b[0m,                            PP: \u001b[32m0.0068\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPR_NOEW --                                        ADF: \u001b[32m0.0013\u001b[0m,                            PP: \u001b[32m0.0004\u001b[0m,                              KPSS: \u001b[32m0.0092\u001b[0m\n",
      "GPRH_AND --                                        ADF: \u001b[32m0.0122\u001b[0m,                            PP: \u001b[32m0.0066\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPR_AND --                                         ADF: \u001b[32m0.0007\u001b[0m,                            PP: \u001b[32m0.0002\u001b[0m,                              KPSS: \u001b[32m0.0313\u001b[0m\n",
      "GPRH_BASIC --                                      ADF: \u001b[32m0.0110\u001b[0m,                            PP: \u001b[32m0.0057\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPR_BASIC --                                       ADF: \u001b[32m0.0090\u001b[0m,                            PP: \u001b[32m0.0045\u001b[0m,                              KPSS: \u001b[32m0.0002\u001b[0m\n",
      "SHAREH_CAT_1 --                                    ADF: \u001b[32m0.0004\u001b[0m,                            PP: \u001b[32m0.0001\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "SHAREH_CAT_2 --                                    ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0456\u001b[0m\n",
      "SHAREH_CAT_3 --                                    ADF: \u001b[32m0.0096\u001b[0m,                            PP: \u001b[32m0.0052\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "SHAREH_CAT_4 --                                    ADF: \u001b[32m0.0011\u001b[0m,                            PP: \u001b[32m0.0003\u001b[0m,                              KPSS: \u001b[32m0.0429\u001b[0m\n",
      "SHAREH_CAT_5 --                                    ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2609\u001b[0m\n",
      "SHAREH_CAT_6 --                                    ADF: \u001b[31m0.4355\u001b[0m,                            PP: \u001b[31m0.4079\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "SHAREH_CAT_7 --                                    ADF: \u001b[32m0.0041\u001b[0m,                            PP: \u001b[32m0.0017\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "SHAREH_CAT_8 --                                    ADF: \u001b[32m0.0012\u001b[0m,                            PP: \u001b[32m0.0004\u001b[0m,                              KPSS: \u001b[32m0.0081\u001b[0m\n",
      "GPRC_ARG --                                        ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0016\u001b[0m\n",
      "GPRC_AUS --                                        ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_BEL --                                        ADF: \u001b[32m0.0091\u001b[0m,                            PP: \u001b[32m0.0045\u001b[0m,                              KPSS: \u001b[32m0.0072\u001b[0m\n",
      "GPRC_BRA --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0350\u001b[0m\n",
      "GPRC_CAN --                                        ADF: \u001b[32m0.0008\u001b[0m,                            PP: \u001b[32m0.0002\u001b[0m,                              KPSS: \u001b[32m0.0131\u001b[0m\n",
      "GPRC_CHE --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1313\u001b[0m\n",
      "GPRC_CHL --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1014\u001b[0m\n",
      "GPRC_CHN --                                        ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0234\u001b[0m\n",
      "GPRC_COL --                                        ADF: \u001b[32m0.0003\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0188\u001b[0m\n",
      "GPRC_DEU --                                        ADF: \u001b[32m0.0271\u001b[0m,                            PP: \u001b[32m0.0176\u001b[0m,                              KPSS: \u001b[32m0.0017\u001b[0m\n",
      "GPRC_DNK --                                        ADF: \u001b[32m0.0005\u001b[0m,                            PP: \u001b[32m0.0001\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_EGY --                                        ADF: \u001b[32m0.0310\u001b[0m,                            PP: \u001b[32m0.0184\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_ESP --                                        ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0009\u001b[0m\n",
      "GPRC_FIN --                                        ADF: \u001b[32m0.0019\u001b[0m,                            PP: \u001b[32m0.0007\u001b[0m,                              KPSS: \u001b[32m0.0019\u001b[0m\n",
      "GPRC_FRA --                                        ADF: \u001b[32m0.0037\u001b[0m,                            PP: \u001b[32m0.0015\u001b[0m,                              KPSS: \u001b[32m0.0084\u001b[0m\n",
      "GPRC_GBR --                                        ADF: \u001b[32m0.0155\u001b[0m,                            PP: \u001b[32m0.0090\u001b[0m,                              KPSS: \u001b[32m0.0010\u001b[0m\n",
      "GPRC_HKG --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0276\u001b[0m\n",
      "GPRC_HUN --                                        ADF: \u001b[32m0.0166\u001b[0m,                            PP: \u001b[32m0.0096\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_IDN --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0002\u001b[0m\n",
      "GPRC_IND --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_ISR --                                        ADF: \u001b[31m0.0569\u001b[0m,                            PP: \u001b[32m0.0369\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_ITA --                                        ADF: \u001b[32m0.0018\u001b[0m,                            PP: \u001b[32m0.0006\u001b[0m,                              KPSS: \u001b[32m0.0030\u001b[0m\n",
      "GPRC_JPN --                                        ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1570\u001b[0m\n",
      "GPRC_KOR --                                        ADF: \u001b[32m0.0063\u001b[0m,                            PP: \u001b[32m0.0031\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_MEX --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_MYS --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.3892\u001b[0m\n",
      "GPRC_NLD --                                        ADF: \u001b[32m0.0009\u001b[0m,                            PP: \u001b[32m0.0002\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_NOR --                                        ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0006\u001b[0m\n",
      "GPRC_PER --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0045\u001b[0m\n",
      "GPRC_PHL --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1905\u001b[0m\n",
      "GPRC_POL --                                        ADF: \u001b[32m0.0346\u001b[0m,                            PP: \u001b[32m0.0234\u001b[0m,                              KPSS: \u001b[32m0.0002\u001b[0m\n",
      "GPRC_PRT --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.1376\u001b[0m\n",
      "GPRC_RUS --                                        ADF: \u001b[31m0.0821\u001b[0m,                            PP: \u001b[31m0.0651\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_SAU --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0033\u001b[0m\n",
      "GPRC_SWE --                                        ADF: \u001b[32m0.0055\u001b[0m,                            PP: \u001b[32m0.0024\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_THA --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.4501\u001b[0m\n",
      "GPRC_TUN --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0036\u001b[0m\n",
      "GPRC_TUR --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2275\u001b[0m\n",
      "GPRC_TWN --                                        ADF: \u001b[32m0.0026\u001b[0m,                            PP: \u001b[32m0.0010\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_UKR --                                        ADF: \u001b[31m0.1684\u001b[0m,                            PP: \u001b[31m0.1492\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_USA --                                        ADF: \u001b[32m0.0060\u001b[0m,                            PP: \u001b[32m0.0027\u001b[0m,                              KPSS: \u001b[32m0.0003\u001b[0m\n",
      "GPRC_VEN --                                        ADF: \u001b[32m0.0002\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRC_VNM --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0004\u001b[0m\n",
      "GPRC_ZAF --                                        ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_ARG --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0969\u001b[0m\n",
      "GPRHC_AUS --                                       ADF: \u001b[32m0.0003\u001b[0m,                            PP: \u001b[32m0.0001\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_BEL --                                       ADF: \u001b[32m0.0030\u001b[0m,                            PP: \u001b[32m0.0011\u001b[0m,                              KPSS: \u001b[32m0.0002\u001b[0m\n",
      "GPRHC_BRA --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0123\u001b[0m\n",
      "GPRHC_CAN --                                       ADF: \u001b[32m0.0004\u001b[0m,                            PP: \u001b[32m0.0001\u001b[0m,                              KPSS: \u001b[32m0.0128\u001b[0m\n",
      "GPRHC_CHE --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0143\u001b[0m\n",
      "GPRHC_CHL --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2596\u001b[0m\n",
      "GPRHC_CHN --                                       ADF: \u001b[32m0.0004\u001b[0m,                            PP: \u001b[32m0.0001\u001b[0m,                              KPSS: \u001b[32m0.0002\u001b[0m\n",
      "GPRHC_COL --                                       ADF: \u001b[32m0.0003\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0865\u001b[0m\n",
      "GPRHC_DEU --                                       ADF: \u001b[32m0.0297\u001b[0m,                            PP: \u001b[32m0.0198\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_DNK --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_EGY --                                       ADF: \u001b[31m0.0590\u001b[0m,                            PP: \u001b[32m0.0396\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_ESP --                                       ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0004\u001b[0m\n",
      "GPRHC_FIN --                                       ADF: \u001b[32m0.0010\u001b[0m,                            PP: \u001b[32m0.0003\u001b[0m,                              KPSS: \u001b[32m0.0023\u001b[0m\n",
      "GPRHC_FRA --                                       ADF: \u001b[32m0.0022\u001b[0m,                            PP: \u001b[32m0.0007\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_GBR --                                       ADF: \u001b[32m0.0116\u001b[0m,                            PP: \u001b[32m0.0063\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_HKG --                                       ADF: \u001b[32m0.0002\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0277\u001b[0m\n",
      "GPRHC_HUN --                                       ADF: \u001b[32m0.0022\u001b[0m,                            PP: \u001b[32m0.0008\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_IDN --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_IND --                                       ADF: \u001b[32m0.0012\u001b[0m,                            PP: \u001b[32m0.0004\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_ISR --                                       ADF: \u001b[31m0.2271\u001b[0m,                            PP: \u001b[31m0.1890\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_ITA --                                       ADF: \u001b[32m0.0007\u001b[0m,                            PP: \u001b[32m0.0002\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_JPN --                                       ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0959\u001b[0m\n",
      "GPRHC_KOR --                                       ADF: \u001b[32m0.0071\u001b[0m,                            PP: \u001b[32m0.0033\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_MEX --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0003\u001b[0m\n",
      "GPRHC_MYS --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0803\u001b[0m\n",
      "GPRHC_NLD --                                       ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_NOR --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0002\u001b[0m\n",
      "GPRHC_PER --                                       ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_PHL --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0733\u001b[0m\n",
      "GPRHC_POL --                                       ADF: \u001b[32m0.0371\u001b[0m,                            PP: \u001b[32m0.0257\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_PRT --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0083\u001b[0m\n",
      "GPRHC_RUS --                                       ADF: \u001b[31m0.1829\u001b[0m,                            PP: \u001b[31m0.1626\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_SAU --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0219\u001b[0m\n",
      "GPRHC_SWE --                                       ADF: \u001b[32m0.0013\u001b[0m,                            PP: \u001b[32m0.0004\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_THA --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2794\u001b[0m\n",
      "GPRHC_TUN --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0635\u001b[0m\n",
      "GPRHC_TUR --                                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.0640\u001b[0m\n",
      "GPRHC_TWN --                                       ADF: \u001b[32m0.0080\u001b[0m,                            PP: \u001b[32m0.0040\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_UKR --                                       ADF: \u001b[31m0.3317\u001b[0m,                            PP: \u001b[31m0.3160\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_USA --                                       ADF: \u001b[32m0.0322\u001b[0m,                            PP: \u001b[32m0.0210\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "GPRHC_VEN --                                       ADF: \u001b[32m0.0001\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0016\u001b[0m\n",
      "GPRHC_VNM --                                       ADF: \u001b[32m0.0004\u001b[0m,                            PP: \u001b[32m0.0001\u001b[0m,                              KPSS: \u001b[32m0.0032\u001b[0m\n",
      "GPRHC_ZAF --                                       ADF: \u001b[32m0.0036\u001b[0m,                            PP: \u001b[32m0.0012\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "MARKET_CAP --                                      ADF: \u001b[31m0.9377\u001b[0m,                            PP: \u001b[31m0.9238\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "CRYPTO_VOLUME_24 --                                ADF: \u001b[31m0.0905\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "WTUI --                                            ADF: \u001b[31m0.3815\u001b[0m,                            PP: \u001b[31m0.3648\u001b[0m,                              KPSS: \u001b[32m0.0001\u001b[0m\n",
      "BTC_DAILY_ABSOLUTE_CHANGE --                       ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.2233\u001b[0m\n",
      "BTC_DAILY_RETURNS_PERC --                          ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.3659\u001b[0m\n",
      "BTC_LOG_DIFFERENCE --                              ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.3014\u001b[0m\n",
      "BTC_PRICE_MIN_7D --                                ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.7113\u001b[0m\n",
      "BTC_PRICE_MAX_7D --                                ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9770\u001b[0m\n",
      "BTC_PRICE_MIN_14D --                               ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9935\u001b[0m\n",
      "BTC_PRICE_MAX_14D --                               ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.5456\u001b[0m\n",
      "BTC_PRICE_MIN_21D --                               ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.3566\u001b[0m\n",
      "BTC_PRICE_MAX_21D --                               ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.7636\u001b[0m\n",
      "BTC_PRICE_MIN_30D --                               ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.7653\u001b[0m\n",
      "BTC_PRICE_MAX_30D --                               ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9229\u001b[0m\n",
      "BTC_PRICE_MIN_60D --                               ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9698\u001b[0m\n",
      "BTC_PRICE_MAX_60D --                               ADF: \u001b[32m0.0000\u001b[0m,                            PP: \u001b[32m0.0000\u001b[0m,                              KPSS: \u001b[31m0.9625\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get the columns that contain numerical data\n",
    "numerical_cols = df_final.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Perform unit root testing on the numerical columns\n",
    "unit_root_testing(df_final[numerical_cols], conf=0.05, tabsize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeskedTesting:\n",
    "\n",
    "    TEST_NAMES = ['White', 'Breusch-Pagan', 'Goldfeld-Quandt']\n",
    "\n",
    "    @staticmethod\n",
    "    def het_tests(series: pd.Series, test: str) -> float:\n",
    "        '''\n",
    "        Testing for heteroskedasticity\n",
    "\n",
    "        :param series: Univariate time series as pd.Series\n",
    "        :param test: String denoting the test. One of 'white','goldfeldquandt', or 'breuschpagan'\n",
    "\n",
    "        :return: p-value as a float.\n",
    "\n",
    "        If the p-value is high, we accept the null hypothesis that the data is homoskedastic\n",
    "        '''\n",
    "        series = series.reset_index(drop=True).reset_index()\n",
    "        series.columns = ['time', 'value']\n",
    "        series['time'] += 1\n",
    "\n",
    "        olsr = ols('value ~ time', series).fit()\n",
    "\n",
    "        if test == 'White':\n",
    "            _, p_value, _, _ = sms.het_white(olsr.resid, olsr.model.exog)\n",
    "        elif test == 'Goldfeld-Quandt':\n",
    "            _, p_value, _ = sms.het_goldfeldquandt(\n",
    "                olsr.resid, olsr.model.exog, alternative='two-sided')\n",
    "        else:\n",
    "            _, p_value, _, _ = sms.het_breuschpagan(\n",
    "                olsr.resid, olsr.model.exog)\n",
    "\n",
    "        return p_value\n",
    "\n",
    "    @classmethod\n",
    "    def run_all_tests(cls, df: pd.DataFrame, conf: float = 0.05, tabsize: int = 30):\n",
    "\n",
    "        print('Results of White, Breusch-Pagan and Goldfeld-Quandt tests by column (p-values):\\n')\n",
    "\n",
    "        for column in df.columns:\n",
    "            p_vals = {}\n",
    "            for test in cls.TEST_NAMES:\n",
    "                p_value = cls.het_tests(df[column].dropna(), test)\n",
    "                if p_value <= conf:\n",
    "                    p_vals[test] = colored(f'{p_value:.4f}', 'red')\n",
    "                else:\n",
    "                    p_vals[test] = colored(f'{p_value:.4f}', 'green')\n",
    "\n",
    "            print(\n",
    "                f'{column} --\\t White: {p_vals[\"White\"]},\\tBreusch-Pagan: {p_vals[\"Breusch-Pagan\"]},\\tGoldfeld-Quandt: {p_vals[\"Goldfeld-Quandt\"]}'.expandtabs(tabsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of White, Breusch-Pagan and Goldfeld-Quandt tests by column (p-values):\n",
      "\n",
      "OPEN --                                                    White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "HIGH --                                                    White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "LOW --                                                     White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "CLOSE --                                                   White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ADJ_CLOSE --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME --                                                  White: \u001b[31m0.0120\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.2480\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GOLD_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SILVER_ADJ_CLOSE --                                        White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.5330\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "OIL_ADJ_CLOSE --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.1327\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GOLD_VOLUME --                                             White: \u001b[31m0.0001\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0011\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SILVER_VOLUME --                                           White: \u001b[32m0.2580\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.1037\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "OIL_VOLUME --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "EUR_USD_ADJ_CLOSE --                                       White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0007\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0002\u001b[0m\n",
      "USD_JPY_ADJ_CLOSE --                                       White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GBP_USD_ADJ_CLOSE --                                       White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USD_CNY_ADJ_CLOSE --                                       White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0023\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VIX_ADJ_CLOSE --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0028\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "CBOE_INTEREST_RATE_ADJ_CLOSE --                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREASURY_YIELD_5YRS_ADJ_CLOSE --                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "RUSSEL_2000_ADJ_CLOSE --                                   White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0011\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ISHARES_20YR_ADJ_CLOSE --                                  White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0098\u001b[0m\n",
      "TREASURY_BILL_13WK_ADJ_CLOSE --                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "RUSSEL_2000_VOLUME --                                      White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.7331\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ISHARES_20YR_VOLUME --                                     White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TESLA_ADJ_CLOSE --                                         White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "AMD_ADJ_CLOSE --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "INTEL_ADJ_CLOSE --                                         White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "APPLE_ADJ_CLOSE --                                         White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.6553\u001b[0m\n",
      "NVIDIA_ADJ_CLOSE --                                        White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "META_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GOOGLE_ADJ_CLOSE --                                        White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TESLA_VOLUME --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "AMD_VOLUME --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "INTEL_VOLUME --                                            White: \u001b[32m0.3499\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.1489\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.9640\u001b[0m\n",
      "APPLE_VOLUME --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "NVIDIA_VOLUME --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "META_VOLUME --                                             White: \u001b[32m0.2266\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.9493\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GOOGLE_VOLUME --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GBTC_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ARKB_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BITB_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "FBTC_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTCO_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "IBIT_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "HODL_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BITO_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GBTC_VOLUME --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ARKB_VOLUME --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BITB_VOLUME --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "FBTC_VOLUME --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTCO_VOLUME --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "IBIT_VOLUME --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "HODL_VOLUME --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0002\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BITO_VOLUME --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ETH_ADJ_CLOSE --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ETH_VOLUME --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USDT_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USDT_VOLUME --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USDC_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USDC_VOLUME --                                             White: \u001b[32m0.3955\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.4564\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "DOGE_ADJ_CLOSE --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0004\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "DOGE_VOLUME --                                             White: \u001b[31m0.0007\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.5427\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "XRP_ADJ_CLOSE --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "XRP_VOLUME --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.8828\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.8107\u001b[0m\n",
      "SOL_ADJ_CLOSE --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SOL_VOLUME --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GAS_ADJ_CLOSE --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GAS_VOLUME --                                              White: \u001b[31m0.0002\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0005\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GAS_USD --                                                 White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "EXTREME_FEAR --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.2955\u001b[0m\n",
      "EXTREME_GREED --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0252\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "FEAR --                                                    White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GREED --                                                   White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "NEUTRAL --                                                 White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SP500_ADJUSTED --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GDP --                                                     White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "RGDP --                                                    White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "UNRATE --                                                  White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "CPI --                                                     White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "INTEREST_RATE_ADJUSTED --                                  White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0002\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREASURE_MATURITY_ADJUSTED --                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "INFLATION_RATE_ADJUSTED --                                 White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "STICKY_CPI --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "M2_MONEY_STOCK_ADJUSTED --                                 White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_ADI --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_OBV --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_CMF --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.9939\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.4270\u001b[0m\n",
      "VOLUME_FI --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0005\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_EM --                                               White: \u001b[31m0.0071\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0263\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_SMA_EM --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_VPT --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_VWAP --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_MFI --                                              White: \u001b[31m0.0021\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0099\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0202\u001b[0m\n",
      "VOLUME_NVI --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_BBM --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_BBH --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_BBL --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_BBW --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_BBP --                                          White: \u001b[32m0.1751\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.8270\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.7994\u001b[0m\n",
      "VOLATILITY_BBHI --                                         White: \u001b[31m0.0314\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0086\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.1711\u001b[0m\n",
      "VOLATILITY_BBLI --                                         White: \u001b[32m0.1001\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.0821\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.8173\u001b[0m\n",
      "VOLATILITY_KCC --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_KCH --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_KCL --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_KCW --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_KCP --                                          White: \u001b[32m0.0513\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0153\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0006\u001b[0m\n",
      "VOLATILITY_KCHI --                                         White: \u001b[32m0.3323\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.8685\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0217\u001b[0m\n",
      "VOLATILITY_KCLI --                                         White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.0555\u001b[0m\n",
      "VOLATILITY_DCL --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_DCH --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_DCM --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_DCW --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_DCP --                                          White: \u001b[32m0.8184\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.5555\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.1560\u001b[0m\n",
      "VOLATILITY_ATR --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_UI --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_MACD --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_MACD_SIGNAL --                                       White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_MACD_DIFF --                                         White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_SMA_FAST --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_SMA_SLOW --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_EMA_FAST --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_EMA_SLOW --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_VORTEX_IND_POS --                                    White: \u001b[31m0.0116\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0033\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0047\u001b[0m\n",
      "TREND_VORTEX_IND_NEG --                                    White: \u001b[32m0.1865\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.0697\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0043\u001b[0m\n",
      "TREND_VORTEX_IND_DIFF --                                   White: \u001b[32m0.0554\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0176\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0057\u001b[0m\n",
      "TREND_TRIX --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_MASS_INDEX --                                        White: \u001b[31m0.0001\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0027\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_DPO --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_KST --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_KST_SIG --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_KST_DIFF --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_ICHIMOKU_CONV --                                     White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_ICHIMOKU_BASE --                                     White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_ICHIMOKU_A --                                        White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_ICHIMOKU_B --                                        White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_STC --                                               White: \u001b[31m0.0403\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.7155\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.8411\u001b[0m\n",
      "TREND_ADX --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.6678\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0001\u001b[0m\n",
      "TREND_ADX_POS --                                           White: \u001b[32m0.2222\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.0829\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0002\u001b[0m\n",
      "TREND_ADX_NEG --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_CCI --                                               White: \u001b[32m0.4608\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.4685\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.6846\u001b[0m\n",
      "TREND_VISUAL_ICHIMOKU_A --                                 White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_VISUAL_ICHIMOKU_B --                                 White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_AROON_UP --                                          White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.3657\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.8297\u001b[0m\n",
      "TREND_AROON_DOWN --                                        White: \u001b[32m0.8749\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.6085\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.0638\u001b[0m\n",
      "TREND_AROON_IND --                                         White: \u001b[32m0.0613\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0242\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.5337\u001b[0m\n",
      "TREND_PSAR_UP --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_PSAR_DOWN --                                         White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_PSAR_UP_INDICATOR --                                 White: \u001b[32m0.9475\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.7886\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.1595\u001b[0m\n",
      "TREND_PSAR_DOWN_INDICATOR --                               White: \u001b[32m0.9725\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.9275\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.1591\u001b[0m\n",
      "MOMENTUM_RSI --                                            White: \u001b[31m0.0256\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.1429\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.8165\u001b[0m\n",
      "MOMENTUM_STOCH_RSI --                                      White: \u001b[32m0.6275\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.8554\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.6606\u001b[0m\n",
      "MOMENTUM_STOCH_RSI_K --                                    White: \u001b[32m0.6305\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.3912\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.4274\u001b[0m\n",
      "MOMENTUM_STOCH_RSI_D --                                    White: \u001b[32m0.4648\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.9084\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.5338\u001b[0m\n",
      "MOMENTUM_TSI --                                            White: \u001b[31m0.0003\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0169\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.9249\u001b[0m\n",
      "MOMENTUM_UO --                                             White: \u001b[31m0.0036\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.0853\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.5411\u001b[0m\n",
      "MOMENTUM_STOCH --                                          White: \u001b[32m0.4673\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.2201\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.5867\u001b[0m\n",
      "MOMENTUM_STOCH_SIGNAL --                                   White: \u001b[32m0.3498\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.1480\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.5191\u001b[0m\n",
      "MOMENTUM_WR --                                             White: \u001b[32m0.4673\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.2201\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.5867\u001b[0m\n",
      "MOMENTUM_AO --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "MOMENTUM_ROC --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "MOMENTUM_PPO --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0001\u001b[0m\n",
      "MOMENTUM_PPO_SIGNAL --                                     White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0010\u001b[0m\n",
      "MOMENTUM_PPO_HIST --                                       White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "MOMENTUM_PVO --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0005\u001b[0m\n",
      "MOMENTUM_PVO_SIGNAL --                                     White: \u001b[31m0.0004\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0066\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.3869\u001b[0m\n",
      "MOMENTUM_PVO_HIST --                                       White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "MOMENTUM_KAMA --                                           White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "OTHERS_DR --                                               White: \u001b[31m0.0001\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "OTHERS_DLR --                                              White: \u001b[31m0.0019\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0005\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "OTHERS_CR --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "UNIQUE_USERS --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "FOLLOWERS --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TWEET_COUNT --                                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTC_PERCENTAGE_DOMINANCE --                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0001\u001b[0m\n",
      "ETH_PERCENTAGE_DOMINANCE --                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USDT_PERCENTAGE_DOMINANCE --                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BNB_PERCENTAGE_DOMINANCE --                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SOL_PERCENTAGE_DOMINANCE --                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "OTHERS_PERCENTAGE_DOMINANCE --                             White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPR --                                                     White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRT --                                                    White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRA --                                                    White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRH --                                                    White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHT --                                                   White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHA --                                                   White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SHARE_GPR --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "N10 --                                                     White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SHARE_GPRH --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "N3H --                                                     White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.2039\u001b[0m\n",
      "GPRH_NOEW --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPR_NOEW --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRH_AND --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPR_AND --                                                 White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0008\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRH_BASIC --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPR_BASIC --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SHAREH_CAT_1 --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SHAREH_CAT_2 --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SHAREH_CAT_3 --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SHAREH_CAT_4 --                                            White: \u001b[31m0.0183\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0052\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SHAREH_CAT_5 --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0003\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SHAREH_CAT_6 --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SHAREH_CAT_7 --                                            White: \u001b[32m0.8177\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.6718\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SHAREH_CAT_8 --                                            White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_ARG --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_AUS --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_BEL --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_BRA --                                                White: \u001b[31m0.0004\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0095\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.8127\u001b[0m\n",
      "GPRC_CAN --                                                White: \u001b[31m0.0043\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.4879\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_CHE --                                                White: \u001b[31m0.0164\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0448\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_CHL --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.8538\u001b[0m\n",
      "GPRC_CHN --                                                White: \u001b[31m0.0430\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.6590\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_COL --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_DEU --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_DNK --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_EGY --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_ESP --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_FIN --                                                White: \u001b[32m0.6677\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.5635\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_FRA --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.0863\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_GBR --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_HKG --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_HUN --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_IDN --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_IND --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.0527\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_ISR --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_ITA --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_JPN --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.0798\u001b[0m\n",
      "GPRC_KOR --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_MEX --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_MYS --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0001\u001b[0m\n",
      "GPRC_NLD --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_NOR --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_PER --                                                White: \u001b[31m0.0013\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0028\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_PHL --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_POL --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_PRT --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0002\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_RUS --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_SAU --                                                White: \u001b[31m0.0007\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0005\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_SWE --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_THA --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_TUN --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.0998\u001b[0m\n",
      "GPRC_TUR --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_TWN --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_UKR --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_USA --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0054\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_VEN --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_VNM --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0042\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRC_ZAF --                                                White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0382\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0004\u001b[0m\n",
      "GPRHC_ARG --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_AUS --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_BEL --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_BRA --                                               White: \u001b[32m0.4980\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.4953\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.2004\u001b[0m\n",
      "GPRHC_CAN --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.1370\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_CHE --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_CHL --                                               White: \u001b[31m0.0004\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0024\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_CHN --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0014\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_COL --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_DEU --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_DNK --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_EGY --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_ESP --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_FIN --                                               White: \u001b[31m0.0097\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.1551\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_FRA --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.8459\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_GBR --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0031\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_HKG --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_HUN --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_IDN --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_IND --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.1508\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0001\u001b[0m\n",
      "GPRHC_ISR --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_ITA --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_JPN --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.3520\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_KOR --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_MEX --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_MYS --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_NLD --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_NOR --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_PER --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_PHL --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_POL --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_PRT --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_RUS --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_SAU --                                               White: \u001b[32m0.8785\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.6169\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_SWE --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_THA --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_TUN --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_TUR --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0303\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0085\u001b[0m\n",
      "GPRHC_TWN --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_UKR --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_USA --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_VEN --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_VNM --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GPRHC_ZAF --                                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "MARKET_CAP --                                              White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "CRYPTO_VOLUME_24 --                                        White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.3179\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "WTUI --                                                    White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTC_DAILY_ABSOLUTE_CHANGE --                               White: \u001b[31m0.0000\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTC_DAILY_RETURNS_PERC --                                  White: \u001b[31m0.0001\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTC_LOG_DIFFERENCE --                                      White: \u001b[31m0.0019\u001b[0m,                                  Breusch-Pagan: \u001b[31m0.0005\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTC_PRICE_MIN_7D --                                        White: \u001b[32m0.8155\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.7586\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.1341\u001b[0m\n",
      "BTC_PRICE_MAX_7D --                                        White: \u001b[32m0.9638\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.8786\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.5234\u001b[0m\n",
      "BTC_PRICE_MIN_14D --                                       White: \u001b[32m0.9848\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.8655\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.1317\u001b[0m\n",
      "BTC_PRICE_MAX_14D --                                       White: \u001b[32m0.7255\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.4254\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTC_PRICE_MIN_21D --                                       White: \u001b[32m0.4817\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.2784\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTC_PRICE_MAX_21D --                                       White: \u001b[32m0.8533\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.5959\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTC_PRICE_MIN_30D --                                       White: \u001b[32m0.5371\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.6110\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.1157\u001b[0m\n",
      "BTC_PRICE_MAX_30D --                                       White: \u001b[32m0.6753\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.6203\u001b[0m,                           Goldfeld-Quandt: \u001b[32m0.1486\u001b[0m\n",
      "BTC_PRICE_MIN_60D --                                       White: \u001b[32m0.9050\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.9461\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0021\u001b[0m\n",
      "BTC_PRICE_MAX_60D --                                       White: \u001b[32m0.8217\u001b[0m,                                  Breusch-Pagan: \u001b[32m0.7111\u001b[0m,                           Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "HeskedTesting.run_all_tests(df_final[numerical_cols], conf=0.05, tabsize=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_difference_dataframe(df: pd.DataFrame, stationary_vars: list):\n",
    "#     ''' \n",
    "#     Returns a dataframe where non-stationary variables are differenced once. \n",
    "#     '''\n",
    "#     # Create an empty dataframe to store the differenced values\n",
    "#     df_differenced = pd.DataFrame(index=df.index)\n",
    "\n",
    "#     # Log-difference non-stationary variables\n",
    "#     for column in df.columns:\n",
    "#         if column not in stationary_vars:\n",
    "#             # Calculate first-order log difference and append it to the dataframe\n",
    "#             df_differenced[column + '_d'] = np.log(df[column].shift(1) + 0.01) - np.log(df[column] + 0.01)\n",
    "\n",
    "#     # Keep stationary variables unchanged\n",
    "#     for column in stationary_vars:\n",
    "#         df_differenced[column] = df[column]\n",
    "\n",
    "#     # Concatenate stationary variables unchanged\n",
    "#     stationary_data = df[stationary_vars].copy()\n",
    "#     df_differenced = pd.concat([df_differenced, stationary_data], axis=1)\n",
    "    \n",
    "#     return df_differenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_difference_dataframe(df: pd.DataFrame, stationary_vars: list):\n",
    "    ''' \n",
    "    Returns a dataframe where non-stationary variables are differenced once. \n",
    "    '''\n",
    "    # Create an empty dataframe to store the differenced values\n",
    "    df_differenced = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # Log-difference non-stationary variables\n",
    "    for column in df.columns:\n",
    "        if column not in stationary_vars:\n",
    "            try:\n",
    "                # Calculate first-order log difference and append it to the dataframe\n",
    "                log_diff = np.log(df[column].shift(1) + 0.01) - np.log(df[column] + 0.01)\n",
    "                df_differenced[column + '_d'] = log_diff\n",
    "            except ValueError:\n",
    "                # Handle invalid values (e.g., skip or replace with a default value)\n",
    "                pass\n",
    "\n",
    "    # Keep stationary variables unchanged\n",
    "    for column in stationary_vars:\n",
    "        df_differenced[column] = df[column]\n",
    "\n",
    "    return df_differenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_target_vars = [\n",
    "    'BTC_DAILY_ABSOLUTE_CHANGE',\n",
    "    'BTC_DAILY_RETURNS_PERC',\n",
    "    'BTC_LOG_DIFFERENCE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "c:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column + '_d'] = log_diff\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column] = df[column]\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column] = df[column]\n",
      "C:\\Users\\Stamatis\\AppData\\Local\\Temp\\ipykernel_131556\\1696167932.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_differenced[column] = df[column]\n"
     ]
    }
   ],
   "source": [
    "btc_differenced_data = log_difference_dataframe(df = df_final[numerical_cols], stationary_vars= btc_target_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEN_d</th>\n",
       "      <th>HIGH_d</th>\n",
       "      <th>LOW_d</th>\n",
       "      <th>CLOSE_d</th>\n",
       "      <th>ADJ_CLOSE_d</th>\n",
       "      <th>VOLUME_d</th>\n",
       "      <th>GOLD_ADJ_CLOSE_d</th>\n",
       "      <th>SILVER_ADJ_CLOSE_d</th>\n",
       "      <th>OIL_ADJ_CLOSE_d</th>\n",
       "      <th>GOLD_VOLUME_d</th>\n",
       "      <th>SILVER_VOLUME_d</th>\n",
       "      <th>OIL_VOLUME_d</th>\n",
       "      <th>EUR_USD_ADJ_CLOSE_d</th>\n",
       "      <th>USD_JPY_ADJ_CLOSE_d</th>\n",
       "      <th>GBP_USD_ADJ_CLOSE_d</th>\n",
       "      <th>USD_CNY_ADJ_CLOSE_d</th>\n",
       "      <th>VIX_ADJ_CLOSE_d</th>\n",
       "      <th>CBOE_INTEREST_RATE_ADJ_CLOSE_d</th>\n",
       "      <th>TREASURY_YIELD_5YRS_ADJ_CLOSE_d</th>\n",
       "      <th>RUSSEL_2000_ADJ_CLOSE_d</th>\n",
       "      <th>ISHARES_20YR_ADJ_CLOSE_d</th>\n",
       "      <th>TREASURY_BILL_13WK_ADJ_CLOSE_d</th>\n",
       "      <th>RUSSEL_2000_VOLUME_d</th>\n",
       "      <th>ISHARES_20YR_VOLUME_d</th>\n",
       "      <th>TESLA_ADJ_CLOSE_d</th>\n",
       "      <th>AMD_ADJ_CLOSE_d</th>\n",
       "      <th>INTEL_ADJ_CLOSE_d</th>\n",
       "      <th>APPLE_ADJ_CLOSE_d</th>\n",
       "      <th>NVIDIA_ADJ_CLOSE_d</th>\n",
       "      <th>META_ADJ_CLOSE_d</th>\n",
       "      <th>GOOGLE_ADJ_CLOSE_d</th>\n",
       "      <th>TESLA_VOLUME_d</th>\n",
       "      <th>AMD_VOLUME_d</th>\n",
       "      <th>INTEL_VOLUME_d</th>\n",
       "      <th>APPLE_VOLUME_d</th>\n",
       "      <th>NVIDIA_VOLUME_d</th>\n",
       "      <th>META_VOLUME_d</th>\n",
       "      <th>GOOGLE_VOLUME_d</th>\n",
       "      <th>GBTC_ADJ_CLOSE_d</th>\n",
       "      <th>ARKB_ADJ_CLOSE_d</th>\n",
       "      <th>BITB_ADJ_CLOSE_d</th>\n",
       "      <th>FBTC_ADJ_CLOSE_d</th>\n",
       "      <th>BTCO_ADJ_CLOSE_d</th>\n",
       "      <th>IBIT_ADJ_CLOSE_d</th>\n",
       "      <th>HODL_ADJ_CLOSE_d</th>\n",
       "      <th>BITO_ADJ_CLOSE_d</th>\n",
       "      <th>GBTC_VOLUME_d</th>\n",
       "      <th>ARKB_VOLUME_d</th>\n",
       "      <th>BITB_VOLUME_d</th>\n",
       "      <th>FBTC_VOLUME_d</th>\n",
       "      <th>BTCO_VOLUME_d</th>\n",
       "      <th>IBIT_VOLUME_d</th>\n",
       "      <th>HODL_VOLUME_d</th>\n",
       "      <th>BITO_VOLUME_d</th>\n",
       "      <th>ETH_ADJ_CLOSE_d</th>\n",
       "      <th>ETH_VOLUME_d</th>\n",
       "      <th>USDT_ADJ_CLOSE_d</th>\n",
       "      <th>USDT_VOLUME_d</th>\n",
       "      <th>USDC_ADJ_CLOSE_d</th>\n",
       "      <th>USDC_VOLUME_d</th>\n",
       "      <th>DOGE_ADJ_CLOSE_d</th>\n",
       "      <th>DOGE_VOLUME_d</th>\n",
       "      <th>XRP_ADJ_CLOSE_d</th>\n",
       "      <th>XRP_VOLUME_d</th>\n",
       "      <th>SOL_ADJ_CLOSE_d</th>\n",
       "      <th>SOL_VOLUME_d</th>\n",
       "      <th>GAS_ADJ_CLOSE_d</th>\n",
       "      <th>GAS_VOLUME_d</th>\n",
       "      <th>GAS_USD_d</th>\n",
       "      <th>EXTREME_FEAR_d</th>\n",
       "      <th>EXTREME_GREED_d</th>\n",
       "      <th>FEAR_d</th>\n",
       "      <th>GREED_d</th>\n",
       "      <th>NEUTRAL_d</th>\n",
       "      <th>SP500_ADJUSTED_d</th>\n",
       "      <th>GDP_d</th>\n",
       "      <th>RGDP_d</th>\n",
       "      <th>UNRATE_d</th>\n",
       "      <th>CPI_d</th>\n",
       "      <th>INTEREST_RATE_ADJUSTED_d</th>\n",
       "      <th>TREASURE_MATURITY_ADJUSTED_d</th>\n",
       "      <th>INFLATION_RATE_ADJUSTED_d</th>\n",
       "      <th>STICKY_CPI_d</th>\n",
       "      <th>M2_MONEY_STOCK_ADJUSTED_d</th>\n",
       "      <th>VOLUME_ADI_d</th>\n",
       "      <th>VOLUME_OBV_d</th>\n",
       "      <th>VOLUME_CMF_d</th>\n",
       "      <th>VOLUME_FI_d</th>\n",
       "      <th>VOLUME_EM_d</th>\n",
       "      <th>VOLUME_SMA_EM_d</th>\n",
       "      <th>VOLUME_VPT_d</th>\n",
       "      <th>VOLUME_VWAP_d</th>\n",
       "      <th>VOLUME_MFI_d</th>\n",
       "      <th>VOLUME_NVI_d</th>\n",
       "      <th>VOLATILITY_BBM_d</th>\n",
       "      <th>VOLATILITY_BBH_d</th>\n",
       "      <th>VOLATILITY_BBL_d</th>\n",
       "      <th>VOLATILITY_BBW_d</th>\n",
       "      <th>VOLATILITY_BBP_d</th>\n",
       "      <th>VOLATILITY_BBHI_d</th>\n",
       "      <th>VOLATILITY_BBLI_d</th>\n",
       "      <th>VOLATILITY_KCC_d</th>\n",
       "      <th>VOLATILITY_KCH_d</th>\n",
       "      <th>VOLATILITY_KCL_d</th>\n",
       "      <th>VOLATILITY_KCW_d</th>\n",
       "      <th>VOLATILITY_KCP_d</th>\n",
       "      <th>VOLATILITY_KCHI_d</th>\n",
       "      <th>VOLATILITY_KCLI_d</th>\n",
       "      <th>VOLATILITY_DCL_d</th>\n",
       "      <th>VOLATILITY_DCH_d</th>\n",
       "      <th>VOLATILITY_DCM_d</th>\n",
       "      <th>VOLATILITY_DCW_d</th>\n",
       "      <th>VOLATILITY_DCP_d</th>\n",
       "      <th>VOLATILITY_ATR_d</th>\n",
       "      <th>VOLATILITY_UI_d</th>\n",
       "      <th>TREND_MACD_d</th>\n",
       "      <th>TREND_MACD_SIGNAL_d</th>\n",
       "      <th>TREND_MACD_DIFF_d</th>\n",
       "      <th>TREND_SMA_FAST_d</th>\n",
       "      <th>TREND_SMA_SLOW_d</th>\n",
       "      <th>TREND_EMA_FAST_d</th>\n",
       "      <th>TREND_EMA_SLOW_d</th>\n",
       "      <th>TREND_VORTEX_IND_POS_d</th>\n",
       "      <th>TREND_VORTEX_IND_NEG_d</th>\n",
       "      <th>TREND_VORTEX_IND_DIFF_d</th>\n",
       "      <th>TREND_TRIX_d</th>\n",
       "      <th>TREND_MASS_INDEX_d</th>\n",
       "      <th>TREND_DPO_d</th>\n",
       "      <th>TREND_KST_d</th>\n",
       "      <th>TREND_KST_SIG_d</th>\n",
       "      <th>TREND_KST_DIFF_d</th>\n",
       "      <th>TREND_ICHIMOKU_CONV_d</th>\n",
       "      <th>TREND_ICHIMOKU_BASE_d</th>\n",
       "      <th>TREND_ICHIMOKU_A_d</th>\n",
       "      <th>TREND_ICHIMOKU_B_d</th>\n",
       "      <th>TREND_STC_d</th>\n",
       "      <th>TREND_ADX_d</th>\n",
       "      <th>TREND_ADX_POS_d</th>\n",
       "      <th>TREND_ADX_NEG_d</th>\n",
       "      <th>TREND_CCI_d</th>\n",
       "      <th>TREND_VISUAL_ICHIMOKU_A_d</th>\n",
       "      <th>TREND_VISUAL_ICHIMOKU_B_d</th>\n",
       "      <th>TREND_AROON_UP_d</th>\n",
       "      <th>TREND_AROON_DOWN_d</th>\n",
       "      <th>TREND_AROON_IND_d</th>\n",
       "      <th>TREND_PSAR_UP_d</th>\n",
       "      <th>TREND_PSAR_DOWN_d</th>\n",
       "      <th>TREND_PSAR_UP_INDICATOR_d</th>\n",
       "      <th>TREND_PSAR_DOWN_INDICATOR_d</th>\n",
       "      <th>MOMENTUM_RSI_d</th>\n",
       "      <th>MOMENTUM_STOCH_RSI_d</th>\n",
       "      <th>MOMENTUM_STOCH_RSI_K_d</th>\n",
       "      <th>MOMENTUM_STOCH_RSI_D_d</th>\n",
       "      <th>MOMENTUM_TSI_d</th>\n",
       "      <th>MOMENTUM_UO_d</th>\n",
       "      <th>MOMENTUM_STOCH_d</th>\n",
       "      <th>MOMENTUM_STOCH_SIGNAL_d</th>\n",
       "      <th>MOMENTUM_WR_d</th>\n",
       "      <th>MOMENTUM_AO_d</th>\n",
       "      <th>MOMENTUM_ROC_d</th>\n",
       "      <th>MOMENTUM_PPO_d</th>\n",
       "      <th>MOMENTUM_PPO_SIGNAL_d</th>\n",
       "      <th>MOMENTUM_PPO_HIST_d</th>\n",
       "      <th>MOMENTUM_PVO_d</th>\n",
       "      <th>MOMENTUM_PVO_SIGNAL_d</th>\n",
       "      <th>MOMENTUM_PVO_HIST_d</th>\n",
       "      <th>MOMENTUM_KAMA_d</th>\n",
       "      <th>OTHERS_DR_d</th>\n",
       "      <th>OTHERS_DLR_d</th>\n",
       "      <th>OTHERS_CR_d</th>\n",
       "      <th>UNIQUE_USERS_d</th>\n",
       "      <th>FOLLOWERS_d</th>\n",
       "      <th>TWEET_COUNT_d</th>\n",
       "      <th>BTC_PERCENTAGE_DOMINANCE_d</th>\n",
       "      <th>ETH_PERCENTAGE_DOMINANCE_d</th>\n",
       "      <th>USDT_PERCENTAGE_DOMINANCE_d</th>\n",
       "      <th>BNB_PERCENTAGE_DOMINANCE_d</th>\n",
       "      <th>SOL_PERCENTAGE_DOMINANCE_d</th>\n",
       "      <th>OTHERS_PERCENTAGE_DOMINANCE_d</th>\n",
       "      <th>GPR_d</th>\n",
       "      <th>GPRT_d</th>\n",
       "      <th>GPRA_d</th>\n",
       "      <th>GPRH_d</th>\n",
       "      <th>GPRHT_d</th>\n",
       "      <th>GPRHA_d</th>\n",
       "      <th>SHARE_GPR_d</th>\n",
       "      <th>N10_d</th>\n",
       "      <th>SHARE_GPRH_d</th>\n",
       "      <th>N3H_d</th>\n",
       "      <th>GPRH_NOEW_d</th>\n",
       "      <th>GPR_NOEW_d</th>\n",
       "      <th>GPRH_AND_d</th>\n",
       "      <th>GPR_AND_d</th>\n",
       "      <th>GPRH_BASIC_d</th>\n",
       "      <th>GPR_BASIC_d</th>\n",
       "      <th>SHAREH_CAT_1_d</th>\n",
       "      <th>SHAREH_CAT_2_d</th>\n",
       "      <th>SHAREH_CAT_3_d</th>\n",
       "      <th>SHAREH_CAT_4_d</th>\n",
       "      <th>SHAREH_CAT_5_d</th>\n",
       "      <th>SHAREH_CAT_6_d</th>\n",
       "      <th>SHAREH_CAT_7_d</th>\n",
       "      <th>SHAREH_CAT_8_d</th>\n",
       "      <th>GPRC_ARG_d</th>\n",
       "      <th>GPRC_AUS_d</th>\n",
       "      <th>GPRC_BEL_d</th>\n",
       "      <th>GPRC_BRA_d</th>\n",
       "      <th>GPRC_CAN_d</th>\n",
       "      <th>GPRC_CHE_d</th>\n",
       "      <th>GPRC_CHL_d</th>\n",
       "      <th>GPRC_CHN_d</th>\n",
       "      <th>GPRC_COL_d</th>\n",
       "      <th>GPRC_DEU_d</th>\n",
       "      <th>GPRC_DNK_d</th>\n",
       "      <th>GPRC_EGY_d</th>\n",
       "      <th>GPRC_ESP_d</th>\n",
       "      <th>GPRC_FIN_d</th>\n",
       "      <th>GPRC_FRA_d</th>\n",
       "      <th>GPRC_GBR_d</th>\n",
       "      <th>GPRC_HKG_d</th>\n",
       "      <th>GPRC_HUN_d</th>\n",
       "      <th>GPRC_IDN_d</th>\n",
       "      <th>GPRC_IND_d</th>\n",
       "      <th>GPRC_ISR_d</th>\n",
       "      <th>GPRC_ITA_d</th>\n",
       "      <th>GPRC_JPN_d</th>\n",
       "      <th>GPRC_KOR_d</th>\n",
       "      <th>GPRC_MEX_d</th>\n",
       "      <th>GPRC_MYS_d</th>\n",
       "      <th>GPRC_NLD_d</th>\n",
       "      <th>GPRC_NOR_d</th>\n",
       "      <th>GPRC_PER_d</th>\n",
       "      <th>GPRC_PHL_d</th>\n",
       "      <th>GPRC_POL_d</th>\n",
       "      <th>GPRC_PRT_d</th>\n",
       "      <th>GPRC_RUS_d</th>\n",
       "      <th>GPRC_SAU_d</th>\n",
       "      <th>GPRC_SWE_d</th>\n",
       "      <th>GPRC_THA_d</th>\n",
       "      <th>GPRC_TUN_d</th>\n",
       "      <th>GPRC_TUR_d</th>\n",
       "      <th>GPRC_TWN_d</th>\n",
       "      <th>GPRC_UKR_d</th>\n",
       "      <th>GPRC_USA_d</th>\n",
       "      <th>GPRC_VEN_d</th>\n",
       "      <th>GPRC_VNM_d</th>\n",
       "      <th>GPRC_ZAF_d</th>\n",
       "      <th>GPRHC_ARG_d</th>\n",
       "      <th>GPRHC_AUS_d</th>\n",
       "      <th>GPRHC_BEL_d</th>\n",
       "      <th>GPRHC_BRA_d</th>\n",
       "      <th>GPRHC_CAN_d</th>\n",
       "      <th>GPRHC_CHE_d</th>\n",
       "      <th>GPRHC_CHL_d</th>\n",
       "      <th>GPRHC_CHN_d</th>\n",
       "      <th>GPRHC_COL_d</th>\n",
       "      <th>GPRHC_DEU_d</th>\n",
       "      <th>GPRHC_DNK_d</th>\n",
       "      <th>GPRHC_EGY_d</th>\n",
       "      <th>GPRHC_ESP_d</th>\n",
       "      <th>GPRHC_FIN_d</th>\n",
       "      <th>GPRHC_FRA_d</th>\n",
       "      <th>GPRHC_GBR_d</th>\n",
       "      <th>GPRHC_HKG_d</th>\n",
       "      <th>GPRHC_HUN_d</th>\n",
       "      <th>GPRHC_IDN_d</th>\n",
       "      <th>GPRHC_IND_d</th>\n",
       "      <th>GPRHC_ISR_d</th>\n",
       "      <th>GPRHC_ITA_d</th>\n",
       "      <th>GPRHC_JPN_d</th>\n",
       "      <th>GPRHC_KOR_d</th>\n",
       "      <th>GPRHC_MEX_d</th>\n",
       "      <th>GPRHC_MYS_d</th>\n",
       "      <th>GPRHC_NLD_d</th>\n",
       "      <th>GPRHC_NOR_d</th>\n",
       "      <th>GPRHC_PER_d</th>\n",
       "      <th>GPRHC_PHL_d</th>\n",
       "      <th>GPRHC_POL_d</th>\n",
       "      <th>GPRHC_PRT_d</th>\n",
       "      <th>GPRHC_RUS_d</th>\n",
       "      <th>GPRHC_SAU_d</th>\n",
       "      <th>GPRHC_SWE_d</th>\n",
       "      <th>GPRHC_THA_d</th>\n",
       "      <th>GPRHC_TUN_d</th>\n",
       "      <th>GPRHC_TUR_d</th>\n",
       "      <th>GPRHC_TWN_d</th>\n",
       "      <th>GPRHC_UKR_d</th>\n",
       "      <th>GPRHC_USA_d</th>\n",
       "      <th>GPRHC_VEN_d</th>\n",
       "      <th>GPRHC_VNM_d</th>\n",
       "      <th>GPRHC_ZAF_d</th>\n",
       "      <th>MARKET_CAP_d</th>\n",
       "      <th>CRYPTO_VOLUME_24_d</th>\n",
       "      <th>WTUI_d</th>\n",
       "      <th>BTC_PRICE_MIN_7D_d</th>\n",
       "      <th>BTC_PRICE_MAX_7D_d</th>\n",
       "      <th>BTC_PRICE_MIN_14D_d</th>\n",
       "      <th>BTC_PRICE_MAX_14D_d</th>\n",
       "      <th>BTC_PRICE_MIN_21D_d</th>\n",
       "      <th>BTC_PRICE_MAX_21D_d</th>\n",
       "      <th>BTC_PRICE_MIN_30D_d</th>\n",
       "      <th>BTC_PRICE_MAX_30D_d</th>\n",
       "      <th>BTC_PRICE_MIN_60D_d</th>\n",
       "      <th>BTC_PRICE_MAX_60D_d</th>\n",
       "      <th>BTC_DAILY_ABSOLUTE_CHANGE</th>\n",
       "      <th>BTC_DAILY_RETURNS_PERC</th>\n",
       "      <th>BTC_LOG_DIFFERENCE</th>\n",
       "      <th>BTC_DAILY_ABSOLUTE_CHANGE</th>\n",
       "      <th>BTC_DAILY_RETURNS_PERC</th>\n",
       "      <th>BTC_LOG_DIFFERENCE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1324.899414</td>\n",
       "      <td>9.701106</td>\n",
       "      <td>0.092589</td>\n",
       "      <td>1324.899414</td>\n",
       "      <td>9.701106</td>\n",
       "      <td>0.092589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>0.035133</td>\n",
       "      <td>-0.090220</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.092589</td>\n",
       "      <td>-0.092589</td>\n",
       "      <td>-0.492860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135143</td>\n",
       "      <td>-0.801104</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>-0.447266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012404</td>\n",
       "      <td>-0.569105</td>\n",
       "      <td>-0.036746</td>\n",
       "      <td>-0.515238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075933</td>\n",
       "      <td>-0.961130</td>\n",
       "      <td>-0.039623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002373</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000804</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-2.001898e-10</td>\n",
       "      <td>-0.009461</td>\n",
       "      <td>-0.001805</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-3.026101</td>\n",
       "      <td>-0.969638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.073034</td>\n",
       "      <td>0.017287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.417462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.047709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.878440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.359895</td>\n",
       "      <td>0.365539</td>\n",
       "      <td>0.375078</td>\n",
       "      <td>0.174937</td>\n",
       "      <td>0.103073</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>0.359763</td>\n",
       "      <td>0.069334</td>\n",
       "      <td>0.173595</td>\n",
       "      <td>0.017022</td>\n",
       "      <td>0.027391</td>\n",
       "      <td>0.222514</td>\n",
       "      <td>0.135083</td>\n",
       "      <td>0.158254</td>\n",
       "      <td>0.183272</td>\n",
       "      <td>0.305475</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>-0.154151</td>\n",
       "      <td>0.051293</td>\n",
       "      <td>0.866811</td>\n",
       "      <td>0.441833</td>\n",
       "      <td>0.318454</td>\n",
       "      <td>0.097638</td>\n",
       "      <td>0.459532</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>-0.139762</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.753772</td>\n",
       "      <td>0.980829</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.350202</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.336472</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.362905</td>\n",
       "      <td>0.070952</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.747214</td>\n",
       "      <td>0.109199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619039</td>\n",
       "      <td>0.626898</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.451985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326903</td>\n",
       "      <td>0.757686</td>\n",
       "      <td>0.356675</td>\n",
       "      <td>-0.182322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04652</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>-0.087011</td>\n",
       "      <td>0.322989</td>\n",
       "      <td>1.011601</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.76214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.396881</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.13815</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275412</td>\n",
       "      <td>0.16508</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>-0.223144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064539</td>\n",
       "      <td>0.505095</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121361</td>\n",
       "      <td>0.446287</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.151231</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.080043</td>\n",
       "      <td>0.167054</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>-0.094137</td>\n",
       "      <td>-0.319645</td>\n",
       "      <td>-0.945546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1324.899414</td>\n",
       "      <td>9.701106</td>\n",
       "      <td>0.092589</td>\n",
       "      <td>1324.899414</td>\n",
       "      <td>9.701106</td>\n",
       "      <td>0.092589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>-0.094689</td>\n",
       "      <td>-0.008266</td>\n",
       "      <td>-0.120174</td>\n",
       "      <td>-0.014505</td>\n",
       "      <td>-0.014505</td>\n",
       "      <td>-0.001501</td>\n",
       "      <td>-0.001901</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>-0.020653</td>\n",
       "      <td>0.481747</td>\n",
       "      <td>2.137863</td>\n",
       "      <td>-0.277997</td>\n",
       "      <td>-0.004274</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>-0.006216</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.065493</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>-0.004770</td>\n",
       "      <td>0.00578</td>\n",
       "      <td>-0.042245</td>\n",
       "      <td>0.635011</td>\n",
       "      <td>0.010281</td>\n",
       "      <td>-0.050565</td>\n",
       "      <td>0.034518</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-0.063726</td>\n",
       "      <td>-0.017755</td>\n",
       "      <td>-0.016277</td>\n",
       "      <td>-0.038162</td>\n",
       "      <td>-1.249877</td>\n",
       "      <td>-1.606224</td>\n",
       "      <td>-0.144129</td>\n",
       "      <td>-0.944749</td>\n",
       "      <td>0.072255</td>\n",
       "      <td>-0.144640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.084802</td>\n",
       "      <td>0.127085</td>\n",
       "      <td>-0.008379</td>\n",
       "      <td>0.064307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009099</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>-0.223704</td>\n",
       "      <td>-0.738441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.076210</td>\n",
       "      <td>0.179346</td>\n",
       "      <td>-0.180606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002356</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000803</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-1.800600e-10</td>\n",
       "      <td>-0.009714</td>\n",
       "      <td>-0.001725</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.034254</td>\n",
       "      <td>-0.483482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.140488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004857</td>\n",
       "      <td>-0.052383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.615121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.887274</td>\n",
       "      <td>1.847883</td>\n",
       "      <td>-0.152764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.900391</td>\n",
       "      <td>1.461080</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>218.900391</td>\n",
       "      <td>1.461080</td>\n",
       "      <td>0.014505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>-0.019340</td>\n",
       "      <td>-0.010660</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>-0.025858</td>\n",
       "      <td>-0.025858</td>\n",
       "      <td>-0.255489</td>\n",
       "      <td>-0.002428</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.006146</td>\n",
       "      <td>3.039773</td>\n",
       "      <td>-2.137863</td>\n",
       "      <td>0.029359</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>-0.003229</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>-0.001398</td>\n",
       "      <td>-0.007613</td>\n",
       "      <td>-0.002439</td>\n",
       "      <td>-0.009261</td>\n",
       "      <td>-0.002020</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.042349</td>\n",
       "      <td>-0.068792</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>-0.048131</td>\n",
       "      <td>0.018504</td>\n",
       "      <td>-0.004633</td>\n",
       "      <td>-0.005257</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>-0.003614</td>\n",
       "      <td>-0.788357</td>\n",
       "      <td>0.341434</td>\n",
       "      <td>0.266728</td>\n",
       "      <td>0.274392</td>\n",
       "      <td>0.449954</td>\n",
       "      <td>0.196007</td>\n",
       "      <td>0.353225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.018730</td>\n",
       "      <td>-0.244344</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>-0.258289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.016631</td>\n",
       "      <td>-0.496277</td>\n",
       "      <td>-0.028873</td>\n",
       "      <td>-0.199825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.062935</td>\n",
       "      <td>-0.172689</td>\n",
       "      <td>-0.096514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002343</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000803</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-1.595023e-10</td>\n",
       "      <td>-0.009881</td>\n",
       "      <td>-0.001633</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.973575</td>\n",
       "      <td>-0.402102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.264970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.017592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.095763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227225</td>\n",
       "      <td>-4.615121</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.580822</td>\n",
       "      <td>-0.575127</td>\n",
       "      <td>-0.229290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.114905</td>\n",
       "      <td>-0.448312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>398.200195</td>\n",
       "      <td>2.619566</td>\n",
       "      <td>0.025858</td>\n",
       "      <td>398.200195</td>\n",
       "      <td>2.619566</td>\n",
       "      <td>0.025858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>-0.013432</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>-0.045801</td>\n",
       "      <td>-0.110944</td>\n",
       "      <td>-0.110944</td>\n",
       "      <td>-0.090264</td>\n",
       "      <td>-0.000682</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.688184</td>\n",
       "      <td>8.131825</td>\n",
       "      <td>0.150319</td>\n",
       "      <td>-0.004812</td>\n",
       "      <td>-0.001562</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009295</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.002754</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.132263</td>\n",
       "      <td>-0.169027</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>0.019984</td>\n",
       "      <td>-0.006951</td>\n",
       "      <td>-0.011318</td>\n",
       "      <td>-0.008437</td>\n",
       "      <td>-0.013578</td>\n",
       "      <td>-0.014463</td>\n",
       "      <td>0.773059</td>\n",
       "      <td>0.540059</td>\n",
       "      <td>0.757513</td>\n",
       "      <td>-0.053181</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>-0.241567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.016980</td>\n",
       "      <td>-0.027347</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.120833</td>\n",
       "      <td>-0.667172</td>\n",
       "      <td>0.047227</td>\n",
       "      <td>0.253593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.055939</td>\n",
       "      <td>-0.023501</td>\n",
       "      <td>-0.085187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002332</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-1.423975e-10</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>-0.001547</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.524910</td>\n",
       "      <td>-0.309221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.761316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.040748</td>\n",
       "      <td>-0.013472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.379355</td>\n",
       "      <td>-4.615121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.065810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.496464</td>\n",
       "      <td>-1.453435</td>\n",
       "      <td>-0.663625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1830.299805</td>\n",
       "      <td>11.733293</td>\n",
       "      <td>0.110945</td>\n",
       "      <td>1830.299805</td>\n",
       "      <td>11.733293</td>\n",
       "      <td>0.110945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OPEN_d    HIGH_d     LOW_d   CLOSE_d  ADJ_CLOSE_d  VOLUME_d  \\\n",
       "DATE                                                                        \n",
       "2018-01-01       NaN       NaN       NaN       NaN          NaN       NaN   \n",
       "2018-01-02  0.035133 -0.090220 -0.000676 -0.092589    -0.092589 -0.492860   \n",
       "2018-01-03 -0.094689 -0.008266 -0.120174 -0.014505    -0.014505 -0.001501   \n",
       "2018-01-04 -0.019340 -0.010660  0.021951 -0.025858    -0.025858 -0.255489   \n",
       "2018-01-05 -0.013432 -0.117672 -0.045801 -0.110944    -0.110944 -0.090264   \n",
       "\n",
       "            GOLD_ADJ_CLOSE_d  SILVER_ADJ_CLOSE_d  OIL_ADJ_CLOSE_d  \\\n",
       "DATE                                                                \n",
       "2018-01-01               NaN                 NaN              NaN   \n",
       "2018-01-02          0.000000            0.000000         0.000000   \n",
       "2018-01-03         -0.001901           -0.003729        -0.020653   \n",
       "2018-01-04         -0.002428           -0.000233        -0.006146   \n",
       "2018-01-05         -0.000682           -0.000930         0.009233   \n",
       "\n",
       "            GOLD_VOLUME_d  SILVER_VOLUME_d  OIL_VOLUME_d  EUR_USD_ADJ_CLOSE_d  \\\n",
       "DATE                                                                            \n",
       "2018-01-01            NaN              NaN           NaN                  NaN   \n",
       "2018-01-02       0.000000         0.000000      0.000000            -0.000548   \n",
       "2018-01-03       0.481747         2.137863     -0.277997            -0.004274   \n",
       "2018-01-04       3.039773        -2.137863      0.029359             0.004369   \n",
       "2018-01-05       0.688184         8.131825      0.150319            -0.004812   \n",
       "\n",
       "            USD_JPY_ADJ_CLOSE_d  GBP_USD_ADJ_CLOSE_d  USD_CNY_ADJ_CLOSE_d  \\\n",
       "DATE                                                                        \n",
       "2018-01-01                  NaN                  NaN                  NaN   \n",
       "2018-01-02            -0.000923             0.000349            -0.000015   \n",
       "2018-01-03             0.004675            -0.006216             0.001813   \n",
       "2018-01-04            -0.003229             0.006216            -0.001398   \n",
       "2018-01-05            -0.001562            -0.003049             0.001506   \n",
       "\n",
       "            VIX_ADJ_CLOSE_d  CBOE_INTEREST_RATE_ADJ_CLOSE_d  \\\n",
       "DATE                                                          \n",
       "2018-01-01              NaN                             NaN   \n",
       "2018-01-02         0.000000                        0.000000   \n",
       "2018-01-03         0.065493                        0.007299   \n",
       "2018-01-04        -0.007613                       -0.002439   \n",
       "2018-01-05         0.000000                       -0.009295   \n",
       "\n",
       "            TREASURY_YIELD_5YRS_ADJ_CLOSE_d  RUSSEL_2000_ADJ_CLOSE_d  \\\n",
       "DATE                                                                   \n",
       "2018-01-01                              NaN                      NaN   \n",
       "2018-01-02                         0.000000                 0.000000   \n",
       "2018-01-03                         0.001328                -0.001657   \n",
       "2018-01-04                        -0.009261                -0.002020   \n",
       "2018-01-05                        -0.007435                -0.002754   \n",
       "\n",
       "            ISHARES_20YR_ADJ_CLOSE_d  TREASURY_BILL_13WK_ADJ_CLOSE_d  \\\n",
       "DATE                                                                   \n",
       "2018-01-01                       NaN                             NaN   \n",
       "2018-01-02                  0.000000                         0.00000   \n",
       "2018-01-03                 -0.004770                         0.00578   \n",
       "2018-01-04                  0.000159                         0.00000   \n",
       "2018-01-05                  0.002860                         0.00000   \n",
       "\n",
       "            RUSSEL_2000_VOLUME_d  ISHARES_20YR_VOLUME_d  TESLA_ADJ_CLOSE_d  \\\n",
       "DATE                                                                         \n",
       "2018-01-01                   NaN                    NaN                NaN   \n",
       "2018-01-02              0.000000               0.000000           0.000000   \n",
       "2018-01-03             -0.042245               0.635011           0.010281   \n",
       "2018-01-04             -0.042349              -0.068792           0.008321   \n",
       "2018-01-05              0.132263              -0.169027          -0.006207   \n",
       "\n",
       "            AMD_ADJ_CLOSE_d  INTEL_ADJ_CLOSE_d  APPLE_ADJ_CLOSE_d  \\\n",
       "DATE                                                                \n",
       "2018-01-01              NaN                NaN                NaN   \n",
       "2018-01-02         0.000000           0.000000           0.000000   \n",
       "2018-01-03        -0.050565           0.034518           0.000174   \n",
       "2018-01-04        -0.048131           0.018504          -0.004633   \n",
       "2018-01-05         0.019984          -0.006951          -0.011318   \n",
       "\n",
       "            NVIDIA_ADJ_CLOSE_d  META_ADJ_CLOSE_d  GOOGLE_ADJ_CLOSE_d  \\\n",
       "DATE                                                                   \n",
       "2018-01-01                 NaN               NaN                 NaN   \n",
       "2018-01-02            0.000000          0.000000            0.000000   \n",
       "2018-01-03           -0.063726         -0.017755           -0.016277   \n",
       "2018-01-04           -0.005257          0.001843           -0.003614   \n",
       "2018-01-05           -0.008437         -0.013578           -0.014463   \n",
       "\n",
       "            TESLA_VOLUME_d  AMD_VOLUME_d  INTEL_VOLUME_d  APPLE_VOLUME_d  \\\n",
       "DATE                                                                       \n",
       "2018-01-01             NaN           NaN             NaN             NaN   \n",
       "2018-01-02        0.000000      0.000000        0.000000        0.000000   \n",
       "2018-01-03       -0.038162     -1.249877       -1.606224       -0.144129   \n",
       "2018-01-04       -0.788357      0.341434        0.266728        0.274392   \n",
       "2018-01-05        0.773059      0.540059        0.757513       -0.053181   \n",
       "\n",
       "            NVIDIA_VOLUME_d  META_VOLUME_d  GOOGLE_VOLUME_d  GBTC_ADJ_CLOSE_d  \\\n",
       "DATE                                                                            \n",
       "2018-01-01              NaN            NaN              NaN               NaN   \n",
       "2018-01-02         0.000000       0.000000         0.000000               0.0   \n",
       "2018-01-03        -0.944749       0.072255        -0.144640               0.0   \n",
       "2018-01-04         0.449954       0.196007         0.353225               0.0   \n",
       "2018-01-05         0.005405       0.022321        -0.241567               0.0   \n",
       "\n",
       "            ARKB_ADJ_CLOSE_d  BITB_ADJ_CLOSE_d  FBTC_ADJ_CLOSE_d  \\\n",
       "DATE                                                               \n",
       "2018-01-01               NaN               NaN               NaN   \n",
       "2018-01-02               0.0               0.0               0.0   \n",
       "2018-01-03               0.0               0.0               0.0   \n",
       "2018-01-04               0.0               0.0               0.0   \n",
       "2018-01-05               0.0               0.0               0.0   \n",
       "\n",
       "            BTCO_ADJ_CLOSE_d  IBIT_ADJ_CLOSE_d  HODL_ADJ_CLOSE_d  \\\n",
       "DATE                                                               \n",
       "2018-01-01               NaN               NaN               NaN   \n",
       "2018-01-02               0.0               0.0               0.0   \n",
       "2018-01-03               0.0               0.0               0.0   \n",
       "2018-01-04               0.0               0.0               0.0   \n",
       "2018-01-05               0.0               0.0               0.0   \n",
       "\n",
       "            BITO_ADJ_CLOSE_d  GBTC_VOLUME_d  ARKB_VOLUME_d  BITB_VOLUME_d  \\\n",
       "DATE                                                                        \n",
       "2018-01-01               NaN            NaN            NaN            NaN   \n",
       "2018-01-02               0.0            0.0            0.0            0.0   \n",
       "2018-01-03               0.0            0.0            0.0            0.0   \n",
       "2018-01-04               0.0            0.0            0.0            0.0   \n",
       "2018-01-05               0.0            0.0            0.0            0.0   \n",
       "\n",
       "            FBTC_VOLUME_d  BTCO_VOLUME_d  IBIT_VOLUME_d  HODL_VOLUME_d  \\\n",
       "DATE                                                                     \n",
       "2018-01-01            NaN            NaN            NaN            NaN   \n",
       "2018-01-02            0.0            0.0            0.0            0.0   \n",
       "2018-01-03            0.0            0.0            0.0            0.0   \n",
       "2018-01-04            0.0            0.0            0.0            0.0   \n",
       "2018-01-05            0.0            0.0            0.0            0.0   \n",
       "\n",
       "            BITO_VOLUME_d  ETH_ADJ_CLOSE_d  ETH_VOLUME_d  USDT_ADJ_CLOSE_d  \\\n",
       "DATE                                                                         \n",
       "2018-01-01            NaN              NaN           NaN               NaN   \n",
       "2018-01-02            0.0        -0.135143     -0.801104          0.002342   \n",
       "2018-01-03            0.0        -0.084802      0.127085         -0.008379   \n",
       "2018-01-04            0.0        -0.018730     -0.244344          0.010717   \n",
       "2018-01-05            0.0        -0.016980     -0.027347          0.003855   \n",
       "\n",
       "            USDT_VOLUME_d  USDC_ADJ_CLOSE_d  USDC_VOLUME_d  DOGE_ADJ_CLOSE_d  \\\n",
       "DATE                                                                           \n",
       "2018-01-01            NaN               NaN            NaN               NaN   \n",
       "2018-01-02      -0.447266               0.0            0.0         -0.012404   \n",
       "2018-01-03       0.064307               0.0            0.0         -0.009099   \n",
       "2018-01-04      -0.258289               0.0            0.0         -0.016631   \n",
       "2018-01-05       0.032880               0.0            0.0         -0.120833   \n",
       "\n",
       "            DOGE_VOLUME_d  XRP_ADJ_CLOSE_d  XRP_VOLUME_d  SOL_ADJ_CLOSE_d  \\\n",
       "DATE                                                                        \n",
       "2018-01-01            NaN              NaN           NaN              NaN   \n",
       "2018-01-02      -0.569105        -0.036746     -0.515238              0.0   \n",
       "2018-01-03       0.298448        -0.223704     -0.738441              0.0   \n",
       "2018-01-04      -0.496277        -0.028873     -0.199825              0.0   \n",
       "2018-01-05      -0.667172         0.047227      0.253593              0.0   \n",
       "\n",
       "            SOL_VOLUME_d  GAS_ADJ_CLOSE_d  GAS_VOLUME_d  GAS_USD_d  \\\n",
       "DATE                                                                 \n",
       "2018-01-01           NaN              NaN           NaN        NaN   \n",
       "2018-01-02           0.0         0.075933     -0.961130  -0.039623   \n",
       "2018-01-03           0.0        -0.076210      0.179346  -0.180606   \n",
       "2018-01-04           0.0        -0.062935     -0.172689  -0.096514   \n",
       "2018-01-05           0.0        -0.055939     -0.023501  -0.085187   \n",
       "\n",
       "            EXTREME_FEAR_d  EXTREME_GREED_d  FEAR_d  GREED_d  NEUTRAL_d  \\\n",
       "DATE                                                                      \n",
       "2018-01-01             NaN              NaN     NaN      NaN        NaN   \n",
       "2018-01-02             0.0              0.0     0.0      0.0        0.0   \n",
       "2018-01-03             0.0              0.0     0.0      0.0        0.0   \n",
       "2018-01-04             0.0              0.0     0.0      0.0        0.0   \n",
       "2018-01-05             0.0              0.0     0.0      0.0        0.0   \n",
       "\n",
       "            SP500_ADJUSTED_d     GDP_d    RGDP_d  UNRATE_d     CPI_d  \\\n",
       "DATE                                                                   \n",
       "2018-01-01               NaN       NaN       NaN       NaN       NaN   \n",
       "2018-01-02         -0.002373 -0.000138 -0.000059 -0.000804 -0.000087   \n",
       "2018-01-03         -0.002356 -0.000138 -0.000059 -0.000803 -0.000087   \n",
       "2018-01-04         -0.002343 -0.000138 -0.000059 -0.000803 -0.000087   \n",
       "2018-01-05         -0.002332 -0.000138 -0.000059 -0.000802 -0.000087   \n",
       "\n",
       "            INTEREST_RATE_ADJUSTED_d  TREASURE_MATURITY_ADJUSTED_d  \\\n",
       "DATE                                                                 \n",
       "2018-01-01                       NaN                           NaN   \n",
       "2018-01-02             -2.001898e-10                     -0.009461   \n",
       "2018-01-03             -1.800600e-10                     -0.009714   \n",
       "2018-01-04             -1.595023e-10                     -0.009881   \n",
       "2018-01-05             -1.423975e-10                     -0.009987   \n",
       "\n",
       "            INFLATION_RATE_ADJUSTED_d  STICKY_CPI_d  \\\n",
       "DATE                                                  \n",
       "2018-01-01                        NaN           NaN   \n",
       "2018-01-02                  -0.001805      0.000517   \n",
       "2018-01-03                  -0.001725      0.000517   \n",
       "2018-01-04                  -0.001633      0.000517   \n",
       "2018-01-05                  -0.001547      0.000518   \n",
       "\n",
       "            M2_MONEY_STOCK_ADJUSTED_d  VOLUME_ADI_d  VOLUME_OBV_d  \\\n",
       "DATE                                                                \n",
       "2018-01-01                        NaN           NaN           NaN   \n",
       "2018-01-02                  -0.000063     -3.026101     -0.969638   \n",
       "2018-01-03                  -0.000065      0.034254     -0.483482   \n",
       "2018-01-04                  -0.000067     -0.973575     -0.402102   \n",
       "2018-01-05                  -0.000066     -0.524910     -0.309221   \n",
       "\n",
       "            VOLUME_CMF_d  VOLUME_FI_d  VOLUME_EM_d  VOLUME_SMA_EM_d  \\\n",
       "DATE                                                                  \n",
       "2018-01-01           NaN          NaN          NaN              NaN   \n",
       "2018-01-02           0.0          0.0     0.000000              NaN   \n",
       "2018-01-03           0.0          0.0     0.843964              NaN   \n",
       "2018-01-04           0.0          0.0          NaN              NaN   \n",
       "2018-01-05           0.0          0.0          NaN              NaN   \n",
       "\n",
       "            VOLUME_VPT_d  VOLUME_VWAP_d  VOLUME_MFI_d  VOLUME_NVI_d  \\\n",
       "DATE                                                                  \n",
       "2018-01-01           NaN            NaN           NaN           NaN   \n",
       "2018-01-02      0.000000            0.0           0.0           0.0   \n",
       "2018-01-03     -0.140488            0.0           0.0           0.0   \n",
       "2018-01-04     -0.264970            0.0           0.0           0.0   \n",
       "2018-01-05     -0.761316            0.0           0.0           0.0   \n",
       "\n",
       "            VOLATILITY_BBM_d  VOLATILITY_BBH_d  VOLATILITY_BBL_d  \\\n",
       "DATE                                                               \n",
       "2018-01-01               NaN               NaN               NaN   \n",
       "2018-01-02               0.0               0.0               0.0   \n",
       "2018-01-03               0.0               0.0               0.0   \n",
       "2018-01-04               0.0               0.0               0.0   \n",
       "2018-01-05               0.0               0.0               0.0   \n",
       "\n",
       "            VOLATILITY_BBW_d  VOLATILITY_BBP_d  VOLATILITY_BBHI_d  \\\n",
       "DATE                                                                \n",
       "2018-01-01               NaN               NaN                NaN   \n",
       "2018-01-02               0.0               0.0                0.0   \n",
       "2018-01-03               0.0               0.0                0.0   \n",
       "2018-01-04               0.0               0.0                0.0   \n",
       "2018-01-05               0.0               0.0                0.0   \n",
       "\n",
       "            VOLATILITY_BBLI_d  VOLATILITY_KCC_d  VOLATILITY_KCH_d  \\\n",
       "DATE                                                                \n",
       "2018-01-01                NaN               NaN               NaN   \n",
       "2018-01-02                0.0               0.0         -0.073034   \n",
       "2018-01-03                0.0               0.0         -0.004857   \n",
       "2018-01-04                0.0               0.0         -0.011389   \n",
       "2018-01-05                0.0               0.0         -0.040748   \n",
       "\n",
       "            VOLATILITY_KCL_d  VOLATILITY_KCW_d  VOLATILITY_KCP_d  \\\n",
       "DATE                                                               \n",
       "2018-01-01               NaN               NaN               NaN   \n",
       "2018-01-02          0.017287               0.0         -0.417462   \n",
       "2018-01-03         -0.052383               0.0         -0.004721   \n",
       "2018-01-04         -0.017592               0.0         -0.095763   \n",
       "2018-01-05         -0.013472               0.0         -0.379355   \n",
       "\n",
       "            VOLATILITY_KCHI_d  VOLATILITY_KCLI_d  VOLATILITY_DCL_d  \\\n",
       "DATE                                                                 \n",
       "2018-01-01                NaN                NaN               NaN   \n",
       "2018-01-02           0.000000                0.0               0.0   \n",
       "2018-01-03           0.000000                0.0               0.0   \n",
       "2018-01-04           0.000000                0.0               0.0   \n",
       "2018-01-05          -4.615121                0.0               0.0   \n",
       "\n",
       "            VOLATILITY_DCH_d  VOLATILITY_DCM_d  VOLATILITY_DCW_d  \\\n",
       "DATE                                                               \n",
       "2018-01-01               NaN               NaN               NaN   \n",
       "2018-01-02               0.0               0.0               0.0   \n",
       "2018-01-03               0.0               0.0               0.0   \n",
       "2018-01-04               0.0               0.0               0.0   \n",
       "2018-01-05               0.0               0.0               0.0   \n",
       "\n",
       "            VOLATILITY_DCP_d  VOLATILITY_ATR_d  VOLATILITY_UI_d  TREND_MACD_d  \\\n",
       "DATE                                                                            \n",
       "2018-01-01               NaN               NaN              NaN           NaN   \n",
       "2018-01-02               0.0               0.0              0.0           NaN   \n",
       "2018-01-03               0.0               0.0              0.0           NaN   \n",
       "2018-01-04               0.0               0.0              0.0           NaN   \n",
       "2018-01-05               0.0               0.0              0.0           NaN   \n",
       "\n",
       "            TREND_MACD_SIGNAL_d  TREND_MACD_DIFF_d  TREND_SMA_FAST_d  \\\n",
       "DATE                                                                   \n",
       "2018-01-01                  NaN                NaN               NaN   \n",
       "2018-01-02                  NaN                NaN               0.0   \n",
       "2018-01-03                  NaN                NaN               0.0   \n",
       "2018-01-04                  NaN                NaN               0.0   \n",
       "2018-01-05                  NaN                NaN               0.0   \n",
       "\n",
       "            TREND_SMA_SLOW_d  TREND_EMA_FAST_d  TREND_EMA_SLOW_d  \\\n",
       "DATE                                                               \n",
       "2018-01-01               NaN               NaN               NaN   \n",
       "2018-01-02               0.0               0.0               0.0   \n",
       "2018-01-03               0.0               0.0               0.0   \n",
       "2018-01-04               0.0               0.0               0.0   \n",
       "2018-01-05               0.0               0.0               0.0   \n",
       "\n",
       "            TREND_VORTEX_IND_POS_d  TREND_VORTEX_IND_NEG_d  \\\n",
       "DATE                                                         \n",
       "2018-01-01                     NaN                     NaN   \n",
       "2018-01-02                     0.0                     0.0   \n",
       "2018-01-03                     0.0                     0.0   \n",
       "2018-01-04                     0.0                     0.0   \n",
       "2018-01-05                     0.0                     0.0   \n",
       "\n",
       "            TREND_VORTEX_IND_DIFF_d  TREND_TRIX_d  TREND_MASS_INDEX_d  \\\n",
       "DATE                                                                    \n",
       "2018-01-01                      NaN           NaN                 NaN   \n",
       "2018-01-02                      0.0           NaN                 0.0   \n",
       "2018-01-03                      0.0           NaN                 0.0   \n",
       "2018-01-04                      0.0           NaN                 0.0   \n",
       "2018-01-05                      0.0           NaN                 0.0   \n",
       "\n",
       "            TREND_DPO_d  TREND_KST_d  TREND_KST_SIG_d  TREND_KST_DIFF_d  \\\n",
       "DATE                                                                      \n",
       "2018-01-01          NaN          NaN              NaN               NaN   \n",
       "2018-01-02          0.0          NaN              NaN               0.0   \n",
       "2018-01-03          0.0          NaN              NaN               0.0   \n",
       "2018-01-04          0.0          NaN              NaN               0.0   \n",
       "2018-01-05          0.0          NaN              NaN               0.0   \n",
       "\n",
       "            TREND_ICHIMOKU_CONV_d  TREND_ICHIMOKU_BASE_d  TREND_ICHIMOKU_A_d  \\\n",
       "DATE                                                                           \n",
       "2018-01-01                    NaN                    NaN                 NaN   \n",
       "2018-01-02                    0.0                    0.0                 0.0   \n",
       "2018-01-03                    0.0                    0.0                 0.0   \n",
       "2018-01-04                    0.0                    0.0                 0.0   \n",
       "2018-01-05                    0.0                    0.0                 0.0   \n",
       "\n",
       "            TREND_ICHIMOKU_B_d  TREND_STC_d  TREND_ADX_d  TREND_ADX_POS_d  \\\n",
       "DATE                                                                        \n",
       "2018-01-01                 NaN          NaN          NaN              NaN   \n",
       "2018-01-02           -0.047709          0.0          0.0              0.0   \n",
       "2018-01-03           -0.004473          0.0          0.0              0.0   \n",
       "2018-01-04           -0.005793          0.0          0.0              0.0   \n",
       "2018-01-05           -0.065810          0.0          0.0              0.0   \n",
       "\n",
       "            TREND_ADX_NEG_d  TREND_CCI_d  TREND_VISUAL_ICHIMOKU_A_d  \\\n",
       "DATE                                                                  \n",
       "2018-01-01              NaN          NaN                        NaN   \n",
       "2018-01-02              0.0          NaN                        0.0   \n",
       "2018-01-03              0.0          NaN                        0.0   \n",
       "2018-01-04              0.0          NaN                        0.0   \n",
       "2018-01-05              0.0          NaN                        0.0   \n",
       "\n",
       "            TREND_VISUAL_ICHIMOKU_B_d  TREND_AROON_UP_d  TREND_AROON_DOWN_d  \\\n",
       "DATE                                                                          \n",
       "2018-01-01                        NaN               NaN                 NaN   \n",
       "2018-01-02                        0.0               0.0                 0.0   \n",
       "2018-01-03                        0.0               0.0                 0.0   \n",
       "2018-01-04                        0.0               0.0                 0.0   \n",
       "2018-01-05                        0.0               0.0                 0.0   \n",
       "\n",
       "            TREND_AROON_IND_d  TREND_PSAR_UP_d  TREND_PSAR_DOWN_d  \\\n",
       "DATE                                                                \n",
       "2018-01-01                NaN              NaN                NaN   \n",
       "2018-01-02                NaN              0.0           0.000000   \n",
       "2018-01-03                NaN              0.0           0.000000   \n",
       "2018-01-04                NaN              0.0          -0.227225   \n",
       "2018-01-05                NaN              0.0           0.000000   \n",
       "\n",
       "            TREND_PSAR_UP_INDICATOR_d  TREND_PSAR_DOWN_INDICATOR_d  \\\n",
       "DATE                                                                 \n",
       "2018-01-01                        NaN                          NaN   \n",
       "2018-01-02                   0.000000                     0.000000   \n",
       "2018-01-03                   0.000000                    -4.615121   \n",
       "2018-01-04                  -4.615121                     4.615121   \n",
       "2018-01-05                   4.615121                     0.000000   \n",
       "\n",
       "            MOMENTUM_RSI_d  MOMENTUM_STOCH_RSI_d  MOMENTUM_STOCH_RSI_K_d  \\\n",
       "DATE                                                                       \n",
       "2018-01-01             NaN                   NaN                     NaN   \n",
       "2018-01-02             0.0                   0.0                     0.0   \n",
       "2018-01-03             0.0                   0.0                     0.0   \n",
       "2018-01-04             0.0                   0.0                     0.0   \n",
       "2018-01-05             0.0                   0.0                     0.0   \n",
       "\n",
       "            MOMENTUM_STOCH_RSI_D_d  MOMENTUM_TSI_d  MOMENTUM_UO_d  \\\n",
       "DATE                                                                \n",
       "2018-01-01                     NaN             NaN            NaN   \n",
       "2018-01-02                     0.0             NaN            0.0   \n",
       "2018-01-03                     0.0             NaN            0.0   \n",
       "2018-01-04                     0.0             NaN            0.0   \n",
       "2018-01-05                     0.0             NaN            0.0   \n",
       "\n",
       "            MOMENTUM_STOCH_d  MOMENTUM_STOCH_SIGNAL_d  MOMENTUM_WR_d  \\\n",
       "DATE                                                                   \n",
       "2018-01-01               NaN                      NaN            NaN   \n",
       "2018-01-02               0.0                      0.0            NaN   \n",
       "2018-01-03               0.0                      0.0            NaN   \n",
       "2018-01-04               0.0                      0.0            NaN   \n",
       "2018-01-05               0.0                      0.0            NaN   \n",
       "\n",
       "            MOMENTUM_AO_d  MOMENTUM_ROC_d  MOMENTUM_PPO_d  \\\n",
       "DATE                                                        \n",
       "2018-01-01            NaN             NaN             NaN   \n",
       "2018-01-02            NaN             0.0             NaN   \n",
       "2018-01-03            NaN             0.0             NaN   \n",
       "2018-01-04            NaN             0.0             NaN   \n",
       "2018-01-05            NaN             0.0             NaN   \n",
       "\n",
       "            MOMENTUM_PPO_SIGNAL_d  MOMENTUM_PPO_HIST_d  MOMENTUM_PVO_d  \\\n",
       "DATE                                                                     \n",
       "2018-01-01                    NaN                  NaN             NaN   \n",
       "2018-01-02                    NaN                  NaN             NaN   \n",
       "2018-01-03                    NaN                  NaN             NaN   \n",
       "2018-01-04                    NaN                  NaN             NaN   \n",
       "2018-01-05                    NaN                  NaN             NaN   \n",
       "\n",
       "            MOMENTUM_PVO_SIGNAL_d  MOMENTUM_PVO_HIST_d  MOMENTUM_KAMA_d  \\\n",
       "DATE                                                                      \n",
       "2018-01-01                    NaN                  NaN              NaN   \n",
       "2018-01-02                    NaN                  0.0              0.0   \n",
       "2018-01-03                    NaN                  0.0              0.0   \n",
       "2018-01-04                    NaN                  0.0              0.0   \n",
       "2018-01-05                    NaN                  0.0              0.0   \n",
       "\n",
       "            OTHERS_DR_d  OTHERS_DLR_d  OTHERS_CR_d  UNIQUE_USERS_d  \\\n",
       "DATE                                                                 \n",
       "2018-01-01          NaN           NaN          NaN             NaN   \n",
       "2018-01-02     0.000000      0.000000    -6.878440             0.0   \n",
       "2018-01-03     1.887274      1.847883    -0.152764             0.0   \n",
       "2018-01-04    -0.580822     -0.575127    -0.229290             0.0   \n",
       "2018-01-05    -1.496464     -1.453435    -0.663625             0.0   \n",
       "\n",
       "            FOLLOWERS_d  TWEET_COUNT_d  BTC_PERCENTAGE_DOMINANCE_d  \\\n",
       "DATE                                                                 \n",
       "2018-01-01          NaN            NaN                         NaN   \n",
       "2018-01-02          0.0            0.0                         0.0   \n",
       "2018-01-03          0.0            0.0                         0.0   \n",
       "2018-01-04          0.0            0.0                         0.0   \n",
       "2018-01-05          0.0            0.0                         0.0   \n",
       "\n",
       "            ETH_PERCENTAGE_DOMINANCE_d  USDT_PERCENTAGE_DOMINANCE_d  \\\n",
       "DATE                                                                  \n",
       "2018-01-01                         NaN                          NaN   \n",
       "2018-01-02                         0.0                          0.0   \n",
       "2018-01-03                         0.0                          0.0   \n",
       "2018-01-04                         0.0                          0.0   \n",
       "2018-01-05                         0.0                          0.0   \n",
       "\n",
       "            BNB_PERCENTAGE_DOMINANCE_d  SOL_PERCENTAGE_DOMINANCE_d  \\\n",
       "DATE                                                                 \n",
       "2018-01-01                         NaN                         NaN   \n",
       "2018-01-02                         0.0                         0.0   \n",
       "2018-01-03                         0.0                         0.0   \n",
       "2018-01-04                         0.0                         0.0   \n",
       "2018-01-05                         0.0                         0.0   \n",
       "\n",
       "            OTHERS_PERCENTAGE_DOMINANCE_d     GPR_d    GPRT_d    GPRA_d  \\\n",
       "DATE                                                                      \n",
       "2018-01-01                            NaN       NaN       NaN       NaN   \n",
       "2018-01-02                            0.0  0.359895  0.365539  0.375078   \n",
       "2018-01-03                            0.0  0.000000  0.000000  0.000000   \n",
       "2018-01-04                            0.0  0.000000  0.000000  0.000000   \n",
       "2018-01-05                            0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "              GPRH_d   GPRHT_d   GPRHA_d  SHARE_GPR_d     N10_d  SHARE_GPRH_d  \\\n",
       "DATE                                                                            \n",
       "2018-01-01       NaN       NaN       NaN          NaN       NaN           NaN   \n",
       "2018-01-02  0.174937  0.103073  0.287346     0.359763  0.069334      0.173595   \n",
       "2018-01-03  0.000000  0.000000  0.000000     0.000000  0.000000      0.000000   \n",
       "2018-01-04  0.000000  0.000000  0.000000     0.000000  0.000000      0.000000   \n",
       "2018-01-05  0.000000  0.000000  0.000000     0.000000  0.000000      0.000000   \n",
       "\n",
       "               N3H_d  GPRH_NOEW_d  GPR_NOEW_d  GPRH_AND_d  GPR_AND_d  \\\n",
       "DATE                                                                   \n",
       "2018-01-01       NaN          NaN         NaN         NaN        NaN   \n",
       "2018-01-02  0.017022     0.027391    0.222514    0.135083   0.158254   \n",
       "2018-01-03  0.000000     0.000000    0.000000    0.000000   0.000000   \n",
       "2018-01-04  0.000000     0.000000    0.000000    0.000000   0.000000   \n",
       "2018-01-05  0.000000     0.000000    0.000000    0.000000   0.000000   \n",
       "\n",
       "            GPRH_BASIC_d  GPR_BASIC_d  SHAREH_CAT_1_d  SHAREH_CAT_2_d  \\\n",
       "DATE                                                                    \n",
       "2018-01-01           NaN          NaN             NaN             NaN   \n",
       "2018-01-02      0.183272     0.305475        0.036368       -0.154151   \n",
       "2018-01-03      0.000000     0.000000        0.000000        0.000000   \n",
       "2018-01-04      0.000000     0.000000        0.000000        0.000000   \n",
       "2018-01-05      0.000000     0.000000        0.000000        0.000000   \n",
       "\n",
       "            SHAREH_CAT_3_d  SHAREH_CAT_4_d  SHAREH_CAT_5_d  SHAREH_CAT_6_d  \\\n",
       "DATE                                                                         \n",
       "2018-01-01             NaN             NaN             NaN             NaN   \n",
       "2018-01-02        0.051293        0.866811        0.441833        0.318454   \n",
       "2018-01-03        0.000000        0.000000        0.000000        0.000000   \n",
       "2018-01-04        0.000000        0.000000        0.000000        0.000000   \n",
       "2018-01-05        0.000000        0.000000        0.000000        0.000000   \n",
       "\n",
       "            SHAREH_CAT_7_d  SHAREH_CAT_8_d  GPRC_ARG_d  GPRC_AUS_d  \\\n",
       "DATE                                                                 \n",
       "2018-01-01             NaN             NaN         NaN         NaN   \n",
       "2018-01-02        0.097638        0.459532   -1.098612    0.916291   \n",
       "2018-01-03        0.000000        0.000000    0.000000    0.000000   \n",
       "2018-01-04        0.000000        0.000000    0.000000    0.000000   \n",
       "2018-01-05        0.000000        0.000000    0.000000    0.000000   \n",
       "\n",
       "            GPRC_BEL_d  GPRC_BRA_d  GPRC_CAN_d  GPRC_CHE_d  GPRC_CHL_d  \\\n",
       "DATE                                                                     \n",
       "2018-01-01         NaN         NaN         NaN         NaN         NaN   \n",
       "2018-01-02   -0.139762    0.182322    0.753772    0.980829    0.405465   \n",
       "2018-01-03    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2018-01-04    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2018-01-05    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            GPRC_CHN_d  GPRC_COL_d  GPRC_DEU_d  GPRC_DNK_d  GPRC_EGY_d  \\\n",
       "DATE                                                                     \n",
       "2018-01-01         NaN         NaN         NaN         NaN         NaN   \n",
       "2018-01-02    0.847298    0.287682    0.350202    0.287682    0.287682   \n",
       "2018-01-03    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2018-01-04    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2018-01-05    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            GPRC_ESP_d  GPRC_FIN_d  GPRC_FRA_d  GPRC_GBR_d  GPRC_HKG_d  \\\n",
       "DATE                                                                     \n",
       "2018-01-01         NaN         NaN         NaN         NaN         NaN   \n",
       "2018-01-02    0.336472    0.693147    0.362905    0.070952    1.098612   \n",
       "2018-01-03    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2018-01-04    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2018-01-05    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            GPRC_HUN_d  GPRC_IDN_d  GPRC_IND_d  GPRC_ISR_d  GPRC_ITA_d  \\\n",
       "DATE                                                                     \n",
       "2018-01-01         NaN         NaN         NaN         NaN         NaN   \n",
       "2018-01-02    0.916291    1.609438    0.747214    0.109199         0.0   \n",
       "2018-01-03    0.000000    0.000000    0.000000    0.000000         0.0   \n",
       "2018-01-04    0.000000    0.000000    0.000000    0.000000         0.0   \n",
       "2018-01-05    0.000000    0.000000    0.000000    0.000000         0.0   \n",
       "\n",
       "            GPRC_JPN_d  GPRC_KOR_d  GPRC_MEX_d  GPRC_MYS_d  GPRC_NLD_d  \\\n",
       "DATE                                                                     \n",
       "2018-01-01         NaN         NaN         NaN         NaN         NaN   \n",
       "2018-01-02    0.619039    0.626898    0.510826    0.916291    0.916291   \n",
       "2018-01-03    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2018-01-04    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2018-01-05    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            GPRC_NOR_d  GPRC_PER_d  GPRC_PHL_d  GPRC_POL_d  GPRC_PRT_d  \\\n",
       "DATE                                                                     \n",
       "2018-01-01         NaN         NaN         NaN         NaN         NaN   \n",
       "2018-01-02    0.693147    0.405465    1.098612    0.451985         0.0   \n",
       "2018-01-03    0.000000    0.000000    0.000000    0.000000         0.0   \n",
       "2018-01-04    0.000000    0.000000    0.000000    0.000000         0.0   \n",
       "2018-01-05    0.000000    0.000000    0.000000    0.000000         0.0   \n",
       "\n",
       "            GPRC_RUS_d  GPRC_SAU_d  GPRC_SWE_d  GPRC_THA_d  GPRC_TUN_d  \\\n",
       "DATE                                                                     \n",
       "2018-01-01         NaN         NaN         NaN         NaN         NaN   \n",
       "2018-01-02    0.326903    0.757686    0.356675   -0.182322         0.0   \n",
       "2018-01-03    0.000000    0.000000    0.000000    0.000000         0.0   \n",
       "2018-01-04    0.000000    0.000000    0.000000    0.000000         0.0   \n",
       "2018-01-05    0.000000    0.000000    0.000000    0.000000         0.0   \n",
       "\n",
       "            GPRC_TUR_d  GPRC_TWN_d  GPRC_UKR_d  GPRC_USA_d  GPRC_VEN_d  \\\n",
       "DATE                                                                     \n",
       "2018-01-01         NaN         NaN         NaN         NaN         NaN   \n",
       "2018-01-02     0.04652    0.510826   -0.087011    0.322989    1.011601   \n",
       "2018-01-03     0.00000    0.000000    0.000000    0.000000    0.000000   \n",
       "2018-01-04     0.00000    0.000000    0.000000    0.000000    0.000000   \n",
       "2018-01-05     0.00000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            GPRC_VNM_d  GPRC_ZAF_d  GPRHC_ARG_d  GPRHC_AUS_d  GPRHC_BEL_d  \\\n",
       "DATE                                                                        \n",
       "2018-01-01         NaN         NaN          NaN          NaN          NaN   \n",
       "2018-01-02    0.693147    1.609438    -1.098612     0.693147      0.76214   \n",
       "2018-01-03    0.000000    0.000000     0.000000     0.000000      0.00000   \n",
       "2018-01-04    0.000000    0.000000     0.000000     0.000000      0.00000   \n",
       "2018-01-05    0.000000    0.000000     0.000000     0.000000      0.00000   \n",
       "\n",
       "            GPRHC_BRA_d  GPRHC_CAN_d  GPRHC_CHE_d  GPRHC_CHL_d  GPRHC_CHN_d  \\\n",
       "DATE                                                                          \n",
       "2018-01-01          NaN          NaN          NaN          NaN          NaN   \n",
       "2018-01-02          0.0     0.287682     1.178655     1.098612     0.396881   \n",
       "2018-01-03          0.0     0.000000     0.000000     0.000000     0.000000   \n",
       "2018-01-04          0.0     0.000000     0.000000     0.000000     0.000000   \n",
       "2018-01-05          0.0     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "            GPRHC_COL_d  GPRHC_DEU_d  GPRHC_DNK_d  GPRHC_EGY_d  GPRHC_ESP_d  \\\n",
       "DATE                                                                          \n",
       "2018-01-01          NaN          NaN          NaN          NaN          NaN   \n",
       "2018-01-02     0.405465      0.13815     0.287682          0.0    -1.386294   \n",
       "2018-01-03     0.000000      0.00000     0.000000          0.0     0.000000   \n",
       "2018-01-04     0.000000      0.00000     0.000000          0.0     0.000000   \n",
       "2018-01-05     0.000000      0.00000     0.000000          0.0     0.000000   \n",
       "\n",
       "            GPRHC_FIN_d  GPRHC_FRA_d  GPRHC_GBR_d  GPRHC_HKG_d  GPRHC_HUN_d  \\\n",
       "DATE                                                                          \n",
       "2018-01-01          NaN          NaN          NaN          NaN          NaN   \n",
       "2018-01-02          0.0     0.275412      0.16508     1.098612     1.386294   \n",
       "2018-01-03          0.0     0.000000      0.00000     0.000000     0.000000   \n",
       "2018-01-04          0.0     0.000000      0.00000     0.000000     0.000000   \n",
       "2018-01-05          0.0     0.000000      0.00000     0.000000     0.000000   \n",
       "\n",
       "            GPRHC_IDN_d  GPRHC_IND_d  GPRHC_ISR_d  GPRHC_ITA_d  GPRHC_JPN_d  \\\n",
       "DATE                                                                          \n",
       "2018-01-01          NaN          NaN          NaN          NaN          NaN   \n",
       "2018-01-02     2.484907     0.575364    -0.223144          0.0     0.064539   \n",
       "2018-01-03     0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "2018-01-04     0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "2018-01-05     0.000000     0.000000     0.000000          0.0     0.000000   \n",
       "\n",
       "            GPRHC_KOR_d  GPRHC_MEX_d  GPRHC_MYS_d  GPRHC_NLD_d  GPRHC_NOR_d  \\\n",
       "DATE                                                                          \n",
       "2018-01-01          NaN          NaN          NaN          NaN          NaN   \n",
       "2018-01-02     0.505095     0.510826     1.386294     2.197225     0.287682   \n",
       "2018-01-03     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2018-01-04     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2018-01-05     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "            GPRHC_PER_d  GPRHC_PHL_d  GPRHC_POL_d  GPRHC_PRT_d  GPRHC_RUS_d  \\\n",
       "DATE                                                                          \n",
       "2018-01-01          NaN          NaN          NaN          NaN          NaN   \n",
       "2018-01-02     0.693147      1.94591    -0.693147          0.0     0.121361   \n",
       "2018-01-03     0.000000      0.00000     0.000000          0.0     0.000000   \n",
       "2018-01-04     0.000000      0.00000     0.000000          0.0     0.000000   \n",
       "2018-01-05     0.000000      0.00000     0.000000          0.0     0.000000   \n",
       "\n",
       "            GPRHC_SAU_d  GPRHC_SWE_d  GPRHC_THA_d  GPRHC_TUN_d  GPRHC_TUR_d  \\\n",
       "DATE                                                                          \n",
       "2018-01-01          NaN          NaN          NaN          NaN          NaN   \n",
       "2018-01-02     0.446287     0.182322     0.405465     1.386294     0.151231   \n",
       "2018-01-03     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2018-01-04     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2018-01-05     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "            GPRHC_TWN_d  GPRHC_UKR_d  GPRHC_USA_d  GPRHC_VEN_d  GPRHC_VNM_d  \\\n",
       "DATE                                                                          \n",
       "2018-01-01          NaN          NaN          NaN          NaN          NaN   \n",
       "2018-01-02    -0.693147    -0.080043     0.167054     1.386294     0.916291   \n",
       "2018-01-03     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2018-01-04     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2018-01-05     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "            GPRHC_ZAF_d  MARKET_CAP_d  CRYPTO_VOLUME_24_d    WTUI_d  \\\n",
       "DATE                                                                  \n",
       "2018-01-01          NaN           NaN                 NaN       NaN   \n",
       "2018-01-02     0.847298     -0.094137           -0.319645 -0.945546   \n",
       "2018-01-03     0.000000      0.000000            0.000000  0.000000   \n",
       "2018-01-04     0.000000     -0.114905           -0.448312  0.000000   \n",
       "2018-01-05     0.000000      0.000000            0.000000  0.000000   \n",
       "\n",
       "            BTC_PRICE_MIN_7D_d  BTC_PRICE_MAX_7D_d  BTC_PRICE_MIN_14D_d  \\\n",
       "DATE                                                                      \n",
       "2018-01-01                 NaN                 NaN                  NaN   \n",
       "2018-01-02                 0.0                 0.0                  0.0   \n",
       "2018-01-03                 0.0                 0.0                  0.0   \n",
       "2018-01-04                 0.0                 0.0                  0.0   \n",
       "2018-01-05                 0.0                 0.0                  0.0   \n",
       "\n",
       "            BTC_PRICE_MAX_14D_d  BTC_PRICE_MIN_21D_d  BTC_PRICE_MAX_21D_d  \\\n",
       "DATE                                                                        \n",
       "2018-01-01                  NaN                  NaN                  NaN   \n",
       "2018-01-02                  0.0                  0.0                  0.0   \n",
       "2018-01-03                  0.0                  0.0                  0.0   \n",
       "2018-01-04                  0.0                  0.0                  0.0   \n",
       "2018-01-05                  0.0                  0.0                  0.0   \n",
       "\n",
       "            BTC_PRICE_MIN_30D_d  BTC_PRICE_MAX_30D_d  BTC_PRICE_MIN_60D_d  \\\n",
       "DATE                                                                        \n",
       "2018-01-01                  NaN                  NaN                  NaN   \n",
       "2018-01-02                  0.0                  0.0                  0.0   \n",
       "2018-01-03                  0.0                  0.0                  0.0   \n",
       "2018-01-04                  0.0                  0.0                  0.0   \n",
       "2018-01-05                  0.0                  0.0                  0.0   \n",
       "\n",
       "            BTC_PRICE_MAX_60D_d  BTC_DAILY_ABSOLUTE_CHANGE  \\\n",
       "DATE                                                         \n",
       "2018-01-01                  NaN                1324.899414   \n",
       "2018-01-02                  0.0                1324.899414   \n",
       "2018-01-03                  0.0                 218.900391   \n",
       "2018-01-04                  0.0                 398.200195   \n",
       "2018-01-05                  0.0                1830.299805   \n",
       "\n",
       "            BTC_DAILY_RETURNS_PERC  BTC_LOG_DIFFERENCE  \\\n",
       "DATE                                                     \n",
       "2018-01-01                9.701106            0.092589   \n",
       "2018-01-02                9.701106            0.092589   \n",
       "2018-01-03                1.461080            0.014505   \n",
       "2018-01-04                2.619566            0.025858   \n",
       "2018-01-05               11.733293            0.110945   \n",
       "\n",
       "            BTC_DAILY_ABSOLUTE_CHANGE  BTC_DAILY_RETURNS_PERC  \\\n",
       "DATE                                                            \n",
       "2018-01-01                1324.899414                9.701106   \n",
       "2018-01-02                1324.899414                9.701106   \n",
       "2018-01-03                 218.900391                1.461080   \n",
       "2018-01-04                 398.200195                2.619566   \n",
       "2018-01-05                1830.299805               11.733293   \n",
       "\n",
       "            BTC_LOG_DIFFERENCE  \n",
       "DATE                            \n",
       "2018-01-01            0.092589  \n",
       "2018-01-02            0.092589  \n",
       "2018-01-03            0.014505  \n",
       "2018-01-04            0.025858  \n",
       "2018-01-05            0.110945  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_differenced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of White, Breusch-Pagan and Goldfeld-Quandt tests by column (p-values):\n",
      "\n",
      "OPEN_d --                                                    White: \u001b[31m0.0017\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0005\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "HIGH_d --                                                    White: \u001b[31m0.0002\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "LOW_d --                                                     White: \u001b[31m0.0040\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0012\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "CLOSE_d --                                                   White: \u001b[31m0.0022\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0006\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ADJ_CLOSE_d --                                               White: \u001b[31m0.0022\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0006\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_d --                                                  White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GOLD_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.6741\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0006\u001b[0m\n",
      "SILVER_ADJ_CLOSE_d --                                        White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.3135\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "OIL_ADJ_CLOSE_d --                                           White: \u001b[31m0.0002\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.2205\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GOLD_VOLUME_d --                                             White: \u001b[31m0.0017\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0160\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0006\u001b[0m\n",
      "SILVER_VOLUME_d --                                           White: \u001b[31m0.0435\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0605\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0006\u001b[0m\n",
      "OIL_VOLUME_d --                                              White: \u001b[31m0.2288\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1076\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "EUR_USD_ADJ_CLOSE_d --                                       White: \u001b[31m0.0279\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0075\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USD_JPY_ADJ_CLOSE_d --                                       White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GBP_USD_ADJ_CLOSE_d --                                       White: \u001b[31m0.1493\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.4808\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.9168\u001b[0m\n",
      "USD_CNY_ADJ_CLOSE_d --                                       White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VIX_ADJ_CLOSE_d --                                           White: \u001b[31m0.0001\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "CBOE_INTEREST_RATE_ADJ_CLOSE_d --                            White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1322\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREASURY_YIELD_5YRS_ADJ_CLOSE_d --                           White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0970\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "RUSSEL_2000_ADJ_CLOSE_d --                                   White: \u001b[31m0.0001\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.6892\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ISHARES_20YR_ADJ_CLOSE_d --                                  White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0002\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREASURY_BILL_13WK_ADJ_CLOSE_d --                            White: \u001b[31m0.1092\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.6390\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "RUSSEL_2000_VOLUME_d --                                      White: \u001b[31m0.0015\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0047\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ISHARES_20YR_VOLUME_d --                                     White: \u001b[31m0.0722\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0368\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0088\u001b[0m\n",
      "TESLA_ADJ_CLOSE_d --                                         White: \u001b[31m0.0002\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.2697\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "AMD_ADJ_CLOSE_d --                                           White: \u001b[31m0.0578\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0170\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "INTEL_ADJ_CLOSE_d --                                         White: \u001b[32m0.5622\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.7443\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0001\u001b[0m\n",
      "APPLE_ADJ_CLOSE_d --                                         White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0321\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "NVIDIA_ADJ_CLOSE_d --                                        White: \u001b[31m0.2366\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.5091\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0990\u001b[0m\n",
      "META_ADJ_CLOSE_d --                                          White: \u001b[31m0.1813\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1038\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GOOGLE_ADJ_CLOSE_d --                                        White: \u001b[31m0.1355\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.2276\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.8247\u001b[0m\n",
      "TESLA_VOLUME_d --                                            White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "AMD_VOLUME_d --                                              White: \u001b[31m0.0001\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "INTEL_VOLUME_d --                                            White: \u001b[32m0.6436\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.3566\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.6158\u001b[0m\n",
      "APPLE_VOLUME_d --                                            White: \u001b[31m0.0144\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0037\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "NVIDIA_VOLUME_d --                                           White: \u001b[31m0.0034\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0015\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "META_VOLUME_d --                                             White: \u001b[32m0.6088\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.3313\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.1078\u001b[0m\n",
      "GOOGLE_VOLUME_d --                                           White: \u001b[32m0.8007\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.5346\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0087\u001b[0m\n",
      "GBTC_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ARKB_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BITB_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "FBTC_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTCO_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "IBIT_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "HODL_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BITO_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GBTC_VOLUME_d --                                             White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ARKB_VOLUME_d --                                             White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BITB_VOLUME_d --                                             White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "FBTC_VOLUME_d --                                             White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BTCO_VOLUME_d --                                             White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "IBIT_VOLUME_d --                                             White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "HODL_VOLUME_d --                                             White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "BITO_VOLUME_d --                                             White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ETH_ADJ_CLOSE_d --                                           White: \u001b[31m0.0001\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "ETH_VOLUME_d --                                              White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USDT_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USDT_VOLUME_d --                                             White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USDC_ADJ_CLOSE_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "USDC_VOLUME_d --                                             White: \u001b[31m0.1723\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.2416\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "DOGE_ADJ_CLOSE_d --                                          White: \u001b[31m0.0012\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1437\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "DOGE_VOLUME_d --                                             White: \u001b[31m0.0021\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0006\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "XRP_ADJ_CLOSE_d --                                           White: \u001b[31m0.0327\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0224\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0001\u001b[0m\n",
      "XRP_VOLUME_d --                                              White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0002\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SOL_ADJ_CLOSE_d --                                           White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "SOL_VOLUME_d --                                              White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GAS_ADJ_CLOSE_d --                                           White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GAS_VOLUME_d --                                              White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GAS_USD_d --                                                 White: \u001b[31m0.4730\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.4779\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0002\u001b[0m\n",
      "EXTREME_FEAR_d --                                            White: \u001b[31m0.0002\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0017\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0658\u001b[0m\n",
      "EXTREME_GREED_d --                                           White: \u001b[31m0.0010\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0060\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "FEAR_d --                                                    White: \u001b[31m0.0001\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0005\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.2090\u001b[0m\n",
      "GREED_d --                                                   White: \u001b[32m0.6959\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.3977\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.6363\u001b[0m\n",
      "NEUTRAL_d --                                                 White: \u001b[32m0.5039\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.2554\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.7321\u001b[0m\n",
      "SP500_ADJUSTED_d --                                          White: \u001b[31m0.0640\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.2566\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "GDP_d --                                                     White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "RGDP_d --                                                    White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "UNRATE_d --                                                  White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0140\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "CPI_d --                                                     White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0678\u001b[0m\n",
      "INTEREST_RATE_ADJUSTED_d --                                  White: \u001b[31m0.0019\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.9807\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREASURE_MATURITY_ADJUSTED_d --                              White: \u001b[31m0.1614\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1098\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "INFLATION_RATE_ADJUSTED_d --                                 White: \u001b[31m0.0546\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.3570\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "STICKY_CPI_d --                                              White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.9605\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.1443\u001b[0m\n",
      "M2_MONEY_STOCK_ADJUSTED_d --                                 White: \u001b[31m0.0671\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1370\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_ADI_d --                                              White: \u001b[31m0.0019\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0259\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_OBV_d --                                              White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_CMF_d --                                              White: \u001b[31m0.4245\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1966\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_FI_d --                                               White: \u001b[31m0.0108\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0493\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_EM_d --                                               White: \u001b[31m0.0982\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0573\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.1263\u001b[0m\n",
      "VOLUME_SMA_EM_d --                                           White: \u001b[31m0.0597\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.5210\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0050\u001b[0m\n",
      "VOLUME_VPT_d --                                              White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_VWAP_d --                                             White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLUME_MFI_d --                                              White: \u001b[31m0.3689\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1610\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.6623\u001b[0m\n",
      "VOLUME_NVI_d --                                              White: \u001b[31m0.0027\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0010\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_BBM_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_BBH_d --                                          White: \u001b[31m0.0017\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0021\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_BBL_d --                                          White: \u001b[31m0.0001\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0001\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_BBW_d --                                          White: \u001b[32m0.6559\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.4643\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.5438\u001b[0m\n",
      "VOLATILITY_BBP_d --                                          White: \u001b[31m0.2415\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1794\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.3394\u001b[0m\n",
      "VOLATILITY_BBHI_d --                                         White: \u001b[31m0.2216\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0940\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0026\u001b[0m\n",
      "VOLATILITY_BBLI_d --                                         White: \u001b[31m0.0512\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0148\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0373\u001b[0m\n",
      "VOLATILITY_KCC_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_KCH_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_KCL_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_KCW_d --                                          White: \u001b[31m0.4444\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.4173\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0008\u001b[0m\n",
      "VOLATILITY_KCP_d --                                          White: \u001b[31m0.3554\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.2384\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.5856\u001b[0m\n",
      "VOLATILITY_KCHI_d --                                         White: \u001b[32m0.9491\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.8799\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0270\u001b[0m\n",
      "VOLATILITY_KCLI_d --                                         White: \u001b[31m0.0396\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0113\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0567\u001b[0m\n",
      "VOLATILITY_DCL_d --                                          White: \u001b[31m0.2430\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1868\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_DCH_d --                                          White: \u001b[31m0.1133\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0803\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_DCM_d --                                          White: \u001b[31m0.0256\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0259\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_DCW_d --                                          White: \u001b[32m0.8171\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.5295\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0001\u001b[0m\n",
      "VOLATILITY_DCP_d --                                          White: \u001b[31m0.3412\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1502\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.6035\u001b[0m\n",
      "VOLATILITY_ATR_d --                                          White: \u001b[31m0.0205\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0845\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "VOLATILITY_UI_d --                                           White: \u001b[32m0.5699\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.3770\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.6766\u001b[0m\n",
      "TREND_MACD_d --                                              White: \u001b[31m0.0416\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0663\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_MACD_SIGNAL_d --                                       White: \u001b[31m0.3722\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.2218\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.3136\u001b[0m\n",
      "TREND_MACD_DIFF_d --                                         White: \u001b[31m0.1252\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0882\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_SMA_FAST_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_SMA_SLOW_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_EMA_FAST_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_EMA_SLOW_d --                                          White: \u001b[31m0.0000\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0000\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_VORTEX_IND_POS_d --                                    White: \u001b[31m0.0703\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0213\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0040\u001b[0m\n",
      "TREND_VORTEX_IND_NEG_d --                                    White: \u001b[31m0.0933\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0295\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_VORTEX_IND_DIFF_d --                                   White: \u001b[31m0.3732\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.5297\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0651\u001b[0m\n",
      "TREND_TRIX_d --                                              White: \u001b[31m0.0158\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0291\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0001\u001b[0m\n",
      "TREND_MASS_INDEX_d --                                        White: \u001b[32m0.6223\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.3594\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_DPO_d --                                               White: \u001b[32m0.7959\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.4997\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.1866\u001b[0m\n",
      "TREND_KST_d --                                               White: \u001b[32m0.6157\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.5861\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_KST_SIG_d --                                           White: \u001b[32m0.9066\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.8771\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_KST_DIFF_d --                                          White: \u001b[32m0.7476\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.7314\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.8464\u001b[0m\n",
      "TREND_ICHIMOKU_CONV_d --                                     White: \u001b[31m0.0026\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0007\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_ICHIMOKU_BASE_d --                                     White: \u001b[31m0.0517\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0547\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_ICHIMOKU_A_d --                                        White: \u001b[31m0.0307\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0501\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_ICHIMOKU_B_d --                                        White: \u001b[31m0.0776\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0489\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_STC_d --                                               White: \u001b[32m0.6269\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.3445\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0003\u001b[0m\n",
      "TREND_ADX_d --                                               White: \u001b[31m0.0274\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0911\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_ADX_POS_d --                                           White: \u001b[31m0.0209\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0796\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_ADX_NEG_d --                                           White: \u001b[31m0.0280\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.1025\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_CCI_d --                                               White: \u001b[32m0.7613\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.4895\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0048\u001b[0m\n",
      "TREND_VISUAL_ICHIMOKU_A_d --                                 White: \u001b[31m0.0327\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0583\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_VISUAL_ICHIMOKU_B_d --                                 White: \u001b[31m0.0281\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0507\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_AROON_UP_d --                                          White: \u001b[31m0.0267\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0079\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0134\u001b[0m\n",
      "TREND_AROON_DOWN_d --                                        White: \u001b[32m0.5157\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.7074\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0067\u001b[0m\n",
      "TREND_AROON_IND_d --                                         White: \u001b[32m0.7676\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.4778\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0297\u001b[0m\n",
      "TREND_PSAR_UP_d --                                           White: \u001b[31m0.1905\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0714\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_PSAR_DOWN_d --                                         White: \u001b[32m0.6191\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.4772\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "TREND_PSAR_UP_INDICATOR_d --                                 White: \u001b[32m0.8900\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.6979\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.1463\u001b[0m\n",
      "TREND_PSAR_DOWN_INDICATOR_d --                               White: \u001b[32m0.9395\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.8952\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.1463\u001b[0m\n",
      "MOMENTUM_RSI_d --                                            White: \u001b[31m0.4965\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.2415\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.1446\u001b[0m\n",
      "MOMENTUM_STOCH_RSI_d --                                      White: \u001b[32m0.8000\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.5324\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.7577\u001b[0m\n",
      "MOMENTUM_STOCH_RSI_K_d --                                    White: \u001b[32m0.9762\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.8285\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.5722\u001b[0m\n",
      "MOMENTUM_STOCH_RSI_D_d --                                    White: \u001b[32m0.9724\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.9958\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0379\u001b[0m\n",
      "MOMENTUM_TSI_d --                                            White: \u001b[31m0.3616\u001b[0m,                                    Breusch-Pagan: \u001b[32m0.7621\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "MOMENTUM_UO_d --                                             White: \u001b[31m0.0278\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0141\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0200\u001b[0m\n",
      "MOMENTUM_STOCH_d --                                          White: \u001b[31m0.4288\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.4304\u001b[0m,                             Goldfeld-Quandt: \u001b[31m0.0000\u001b[0m\n",
      "MOMENTUM_STOCH_SIGNAL_d --                                   White: \u001b[31m0.0653\u001b[0m,                                    Breusch-Pagan: \u001b[31m0.0197\u001b[0m,                             Goldfeld-Quandt: \u001b[32m0.7583\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m btc_differenced_data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mHeskedTesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbtc_differenced_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtabsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataframe is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[43], line 42\u001b[0m, in \u001b[0;36mHeskedTesting.run_all_tests\u001b[1;34m(cls, df, conf, tabsize)\u001b[0m\n\u001b[0;32m     40\u001b[0m p_vals \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mTEST_NAMES:\n\u001b[1;32m---> 42\u001b[0m     p_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhet_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_value \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m conf:\n\u001b[0;32m     44\u001b[0m         p_vals[test] \u001b[38;5;241m=\u001b[39m colored(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[43], line 21\u001b[0m, in \u001b[0;36mHeskedTesting.het_tests\u001b[1;34m(series, test)\u001b[0m\n\u001b[0;32m     18\u001b[0m series\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m series[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 21\u001b[0m olsr \u001b[38;5;241m=\u001b[39m \u001b[43mols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue ~ time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhite\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     24\u001b[0m     _, p_value, _, _ \u001b[38;5;241m=\u001b[39m sms\u001b[38;5;241m.\u001b[39mhet_white(olsr\u001b[38;5;241m.\u001b[39mresid, olsr\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mexog)\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\base\\model.py:229\u001b[0m, in \u001b[0;36mModel.from_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         design_info \u001b[38;5;241m=\u001b[39m design_info\u001b[38;5;241m.\u001b[39msubset(cols)\n\u001b[0;32m    225\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing_idx\u001b[39m\u001b[38;5;124m'\u001b[39m: missing_idx,\n\u001b[0;32m    226\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m: missing,\n\u001b[0;32m    227\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformula\u001b[39m\u001b[38;5;124m'\u001b[39m: formula,  \u001b[38;5;66;03m# attach formula for unpckling\u001b[39;00m\n\u001b[0;32m    228\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesign_info\u001b[39m\u001b[38;5;124m'\u001b[39m: design_info})\n\u001b[1;32m--> 229\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    230\u001b[0m mod\u001b[38;5;241m.\u001b[39mformula \u001b[38;5;241m=\u001b[39m formula\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# since we got a dataframe, attach the original\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:923\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    921\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    922\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[1;32m--> 923\u001b[0m \u001b[38;5;28msuper\u001b[39m(OLS, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    924\u001b[0m                           hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:748\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28msuper\u001b[39m(WLS, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    749\u001b[0m                           weights\u001b[38;5;241m=\u001b[39mweights, hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    750\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    751\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:202\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28msuper\u001b[39m(RegressionModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog: Float64Array \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m     96\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(endog, exog\u001b[38;5;241m=\u001b[39mexog, missing\u001b[38;5;241m=\u001b[39mmissing, hasconst\u001b[38;5;241m=\u001b[39mhasconst,\n\u001b[0;32m    676\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\base\\data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity()\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\base\\data.py:132\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# detect where the constant is\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     check_implicit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     exog_max \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(exog_max)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MissingDataError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexog contains inf or nans\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2810\u001b[0m, in \u001b[0;36mmax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[0;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2698\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2811\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Stamatis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "HeskedTesting.run_all_tests(btc_differenced_data, conf=0.5, tabsize=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
